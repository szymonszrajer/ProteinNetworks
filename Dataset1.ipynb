{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "9y_pYezV4YcN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJtiQWfpPThQ"
      },
      "outputs": [],
      "source": [
        "%pip install Bio\n",
        "from Bio.SeqUtils import IsoelectricPoint\n",
        "from Bio.Seq import Seq\n",
        "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
        "import statistics\n",
        "!apt-get update\n",
        "!apt-get install emboss\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from Bio import SeqIO\n",
        "from typing import Sequence\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dropout, Dense, ReLU, Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.activations import sigmoid\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing out the ProtParam"
      ],
      "metadata": {
        "id": "fEKDpkFE4l1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a protein sequence object\n",
        "sequence = Seq(\"MAEGEITTFTALTEKFNLPPGNYKKPKLLYCSNGGHFLRILPDGTVDGTRDRSDQHIQLQLSAESVGEVYIKSTETGQYLAMDTSGLLYGSQTPSEECLFLERLEENHYNTYTSKKHAEKNWFVGLKKNGSCKRGPRTHYGQKAILFLPLPV\")\n",
        "\n",
        "# Calculate the statistics\n",
        "stats = ProteinAnalysis(sequence)\n",
        "\n",
        "# Print the results\n",
        "count = stats.count_amino_acids()\n",
        "percent = stats.get_amino_acids_percent()\n",
        "print(stats.molecular_weight())\n",
        "print(stats.aromaticity())\n",
        "print(stats.instability_index())\n",
        "sec_struc = stats.secondary_structure_fraction()  # [helix, turn, sheet]\n",
        "print(\"%0.2f\" % sec_struc[0])  # helix\n",
        "print(\"%0.2f\" % sec_struc[1])  # turn\n",
        "print(\"%0.2f\" % sec_struc[2])  # sheet\n",
        "epsilon_prot = stats.molar_extinction_coefficient()  # [reduced, oxidized]\n",
        "print(epsilon_prot[0])  # with reduced cysteines\n",
        "charge = stats.charge_at_pH(10)\n",
        "print(charge)\n",
        "charge = stats.charge_at_pH(7)\n",
        "print(charge)\n",
        "charge = stats.charge_at_pH(4)\n",
        "print(charge)\n",
        "isoelectric = stats.isoelectric_point()\n",
        "print(isoelectric)\n",
        "gravy = stats.gravy()\n",
        "print(gravy)\n",
        "flex = stats.flexibility()\n",
        "print(statistics.mean(flex))\n",
        "print(stats.molecular_weight() / sum(count.values()))\n",
        "\n",
        "tiny = percent[\"A\"] + percent[\"C\"] + percent[\"G\"] + percent[\"S\"] + percent[\"T\"]  \n",
        "small = percent[\"A\"] + percent[\"C\"] + percent[\"D\"] + percent[\"G\"] \\\n",
        "      + percent[\"N\"] + percent[\"P\"] + percent[\"S\"] + percent[\"T\"] + percent[\"V\"]\n",
        "aliphatic = percent[\"A\"] + percent[\"I\"] + percent[\"L\"] + percent[\"V\"]   \n",
        "aromatic = percent[\"F\"] + percent[\"H\"] + percent[\"W\"] + percent[\"Y\"]   \n",
        "non_polar = percent[\"A\"] + percent[\"C\"] + percent[\"F\"] + percent[\"G\"] + percent[\"I\"] \\\n",
        "          + percent[\"L\"] + percent[\"M\"] + percent[\"P\"] + percent[\"V\"] + percent[\"W\"] \\\n",
        "          + percent[\"Y\"] \n",
        "polar = percent[\"D\"] + percent[\"E\"] + percent[\"H\"] + percent[\"K\"] + percent[\"N\"] \\\n",
        "      + percent[\"Q\"] + percent[\"R\"] + percent[\"S\"] + percent[\"T\"] \n",
        "charged = percent[\"D\"] + percent[\"E\"] + percent[\"H\"] + percent[\"K\"] + percent[\"R\"] \n",
        "basic = percent[\"H\"] + percent[\"K\"] + percent[\"R\"]  \n",
        "acidic = percent[\"D\"] + percent[\"E\"]   \n",
        "ala = percent[\"A\"] \n",
        "arg = percent[\"R\"] \n",
        "asn = percent[\"N\"] \n",
        "asp = percent[\"D\"] \n",
        "cys = percent[\"C\"] "
      ],
      "metadata": {
        "id": "tSajIPTkMNkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "077dbf7e-5869-4bb5-b5a3-5aeea233e907"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17103.1617\n",
            "0.09868421052631579\n",
            "41.980263157894726\n",
            "0.28\n",
            "0.26\n",
            "0.25\n",
            "17420\n",
            "-12.785162430771866\n",
            "0.9258119875149688\n",
            "17.71008924714465\n",
            "7.7224523544311525\n",
            "-0.597368421052632\n",
            "1.0058031968031969\n",
            "112.52080065789474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Data"
      ],
      "metadata": {
        "id": "IcDG6_il4rhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory = '/content'\n",
        "data = []\n",
        "\n",
        "for file in os.listdir(directory):\n",
        "    if file.endswith('.fa'):\n",
        "        ix = 0\n",
        "        for record in SeqIO.parse(os.path.join(directory, file), 'fasta'):\n",
        "            sequence = str(record.seq)\n",
        "            function = file.split('_')[0]\n",
        "            index = f\"{function}_{ix}\"\n",
        "            data.append({'Sequence': sequence, 'Class': function, 'Index': index})\n",
        "            ix += 1\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.set_index('Index', inplace=True)\n"
      ],
      "metadata": {
        "id": "Iah3pWaaHp1f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "7cawbFvu3Pqi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "09aa0062-1e64-4b46-b453-9f0bc26d7055"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Sequence Class\n",
              "Index                                                          \n",
              "5_0     MSGDHSHNEDQIMGGSRINDSHKHKDKYKEHKHKDYKRDKEREKSK...     5\n",
              "5_1     MSGDHSHNEDQIMGGSRNNDSHKHKDKYKEHKHKDYKRDKEREKSK...     5\n",
              "5_2     MVGAAFVRPKRSPQRGDGVGRMLGGSRAVGTCGYGVNMRCLAARVN...     5\n",
              "5_3     VGEGCDVPCLRRRGGPYKTAAATDLSRWRLSNVEGRQSWSFVDQRD...     5\n",
              "5_4     MTEGTHLRRRGGPYKSDPATDLSRWRLTNDEGRQTWRYVEDQDSPD...     5\n",
              "...                                                   ...   ...\n",
              "4_1995  MAGRVPSLLVLLLVFPSSCLAFRSPLSVFKRFKETTRPLSNECLGT...     4\n",
              "4_1996  MNLPPCRLWRPLTSRLGQRQPQPRAGARSCPLPARGRARPLCGRPH...     4\n",
              "4_1997  NVSMDTWNFSYTCLVSLWLHRFYIYSVVAFGISVWIIIQFFTTKTK...     4\n",
              "4_1998  MFCAKLKDLQITGDCPFSLLAPGQVPREPLGEATGSGPASTPGQPG...     4\n",
              "4_1999  MRVPVFYAVVLAFFCHSDSLEIQPSLYGSTRSQEAILNPSDCSART...     4\n",
              "\n",
              "[28000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-812afeed-2552-41e0-a6b3-75eb3afa842d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sequence</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5_0</th>\n",
              "      <td>MSGDHSHNEDQIMGGSRINDSHKHKDKYKEHKHKDYKRDKEREKSK...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_1</th>\n",
              "      <td>MSGDHSHNEDQIMGGSRNNDSHKHKDKYKEHKHKDYKRDKEREKSK...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_2</th>\n",
              "      <td>MVGAAFVRPKRSPQRGDGVGRMLGGSRAVGTCGYGVNMRCLAARVN...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_3</th>\n",
              "      <td>VGEGCDVPCLRRRGGPYKTAAATDLSRWRLSNVEGRQSWSFVDQRD...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_4</th>\n",
              "      <td>MTEGTHLRRRGGPYKSDPATDLSRWRLTNDEGRQTWRYVEDQDSPD...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1995</th>\n",
              "      <td>MAGRVPSLLVLLLVFPSSCLAFRSPLSVFKRFKETTRPLSNECLGT...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1996</th>\n",
              "      <td>MNLPPCRLWRPLTSRLGQRQPQPRAGARSCPLPARGRARPLCGRPH...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1997</th>\n",
              "      <td>NVSMDTWNFSYTCLVSLWLHRFYIYSVVAFGISVWIIIQFFTTKTK...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1998</th>\n",
              "      <td>MFCAKLKDLQITGDCPFSLLAPGQVPREPLGEATGSGPASTPGQPG...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1999</th>\n",
              "      <td>MRVPVFYAVVLAFFCHSDSLEIQPSLYGSTRSQEAILNPSDCSART...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-812afeed-2552-41e0-a6b3-75eb3afa842d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-812afeed-2552-41e0-a6b3-75eb3afa842d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-812afeed-2552-41e0-a6b3-75eb3afa842d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare Binary for binary classification"
      ],
      "metadata": {
        "id": "25gIrck2qahT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Class'] = df['Class'].str.replace('non-enzyme', '8')\n"
      ],
      "metadata": {
        "id": "x3uMehoT3UWg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Binary'] = df['Class'].apply(lambda x: 1 if x in [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"] else 0)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "9pX76afvALav",
        "outputId": "38b37c77-4f70-4394-c6dc-17473c709491"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Sequence Class  Binary\n",
              "Index                                                                  \n",
              "5_0     MSGDHSHNEDQIMGGSRINDSHKHKDKYKEHKHKDYKRDKEREKSK...     5       1\n",
              "5_1     MSGDHSHNEDQIMGGSRNNDSHKHKDKYKEHKHKDYKRDKEREKSK...     5       1\n",
              "5_2     MVGAAFVRPKRSPQRGDGVGRMLGGSRAVGTCGYGVNMRCLAARVN...     5       1\n",
              "5_3     VGEGCDVPCLRRRGGPYKTAAATDLSRWRLSNVEGRQSWSFVDQRD...     5       1\n",
              "5_4     MTEGTHLRRRGGPYKSDPATDLSRWRLTNDEGRQTWRYVEDQDSPD...     5       1\n",
              "...                                                   ...   ...     ...\n",
              "4_1995  MAGRVPSLLVLLLVFPSSCLAFRSPLSVFKRFKETTRPLSNECLGT...     4       1\n",
              "4_1996  MNLPPCRLWRPLTSRLGQRQPQPRAGARSCPLPARGRARPLCGRPH...     4       1\n",
              "4_1997  NVSMDTWNFSYTCLVSLWLHRFYIYSVVAFGISVWIIIQFFTTKTK...     4       1\n",
              "4_1998  MFCAKLKDLQITGDCPFSLLAPGQVPREPLGEATGSGPASTPGQPG...     4       1\n",
              "4_1999  MRVPVFYAVVLAFFCHSDSLEIQPSLYGSTRSQEAILNPSDCSART...     4       1\n",
              "\n",
              "[28000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e85ea7a2-3a24-4240-991e-b62fd01ad3e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sequence</th>\n",
              "      <th>Class</th>\n",
              "      <th>Binary</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5_0</th>\n",
              "      <td>MSGDHSHNEDQIMGGSRINDSHKHKDKYKEHKHKDYKRDKEREKSK...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_1</th>\n",
              "      <td>MSGDHSHNEDQIMGGSRNNDSHKHKDKYKEHKHKDYKRDKEREKSK...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_2</th>\n",
              "      <td>MVGAAFVRPKRSPQRGDGVGRMLGGSRAVGTCGYGVNMRCLAARVN...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_3</th>\n",
              "      <td>VGEGCDVPCLRRRGGPYKTAAATDLSRWRLSNVEGRQSWSFVDQRD...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_4</th>\n",
              "      <td>MTEGTHLRRRGGPYKSDPATDLSRWRLTNDEGRQTWRYVEDQDSPD...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1995</th>\n",
              "      <td>MAGRVPSLLVLLLVFPSSCLAFRSPLSVFKRFKETTRPLSNECLGT...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1996</th>\n",
              "      <td>MNLPPCRLWRPLTSRLGQRQPQPRAGARSCPLPARGRARPLCGRPH...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1997</th>\n",
              "      <td>NVSMDTWNFSYTCLVSLWLHRFYIYSVVAFGISVWIIIQFFTTKTK...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1998</th>\n",
              "      <td>MFCAKLKDLQITGDCPFSLLAPGQVPREPLGEATGSGPASTPGQPG...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1999</th>\n",
              "      <td>MRVPVFYAVVLAFFCHSDSLEIQPSLYGSTRSQEAILNPSDCSART...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e85ea7a2-3a24-4240-991e-b62fd01ad3e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e85ea7a2-3a24-4240-991e-b62fd01ad3e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e85ea7a2-3a24-4240-991e-b62fd01ad3e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the stats table"
      ],
      "metadata": {
        "id": "34X2jCXFwlaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.reset_index()\n",
        "df[\"Sequence\"] = df[\"Sequence\"].str.replace(\"X\", \"\")\n",
        "df[\"Sequence\"] = df[\"Sequence\"].str.replace(\"U\", \"C\")\n",
        "\n",
        "# Iterate through the rows of the DataFrame and create new objects\n",
        "statistical = []\n",
        "for i, row in df.iterrows():\n",
        "    obj_stats = []\n",
        "    stats = ProteinAnalysis(row[\"Sequence\"])\n",
        "    count = stats.count_amino_acids()\n",
        "    percent = stats.get_amino_acids_percent()\n",
        "    obj_stats.append(round(stats.molecular_weight(),2))\n",
        "    obj_stats.append(round(stats.aromaticity(),2))\n",
        "    obj_stats.append(round(stats.instability_index(),2))\n",
        "    sec_struc = stats.secondary_structure_fraction()  # [helix, turn, sheet]\n",
        "    obj_stats.append(round(sec_struc[0],2))\n",
        "    obj_stats.append(round(sec_struc[1],2))\n",
        "    obj_stats.append(round(sec_struc[2],2))\n",
        "\n",
        "    obj_stats.append(round(stats.molar_extinction_coefficient()[0],2))\n",
        "    obj_stats.append(round(stats.charge_at_pH(10),2))\n",
        "    obj_stats.append(round(stats.charge_at_pH(7),2))\n",
        "    obj_stats.append(round(stats.charge_at_pH(4),2))\n",
        "\n",
        "    obj_stats.append(round(stats.isoelectric_point(),2))\n",
        "    obj_stats.append(round(stats.gravy(),2))\n",
        "\n",
        "    flex = stats.flexibility()\n",
        "\n",
        "    obj_stats.append(round(statistics.mean(flex),2))\n",
        "    obj_stats.append(round(stats.molecular_weight() / sum(count.values()),2))\n",
        "\n",
        "    obj_stats.append(round(percent[\"A\"] + percent[\"C\"] + percent[\"G\"] \\\n",
        "                         + percent[\"S\"] + percent[\"T\"],2))\n",
        "    \n",
        "    obj_stats.append(round(percent[\"A\"] + percent[\"C\"] + percent[\"D\"] \\\n",
        "                         + percent[\"G\"] + percent[\"N\"] + percent[\"P\"] \\\n",
        "                         + percent[\"S\"] + percent[\"T\"] + percent[\"V\"],2))\n",
        "    \n",
        "    obj_stats.append(round( percent[\"A\"] + percent[\"I\"] + percent[\"L\"] \\\n",
        "                          + percent[\"V\"] ,2))\n",
        "\n",
        "    obj_stats.append(round( percent[\"F\"] + percent[\"H\"] + percent[\"W\"] \\\n",
        "                          + percent[\"Y\"] ,2))\n",
        "    \n",
        "    obj_stats.append(round( percent[\"A\"] + percent[\"C\"] + percent[\"F\"] \\\n",
        "                          + percent[\"G\"] + percent[\"I\"] + percent[\"L\"] \\\n",
        "                          + percent[\"M\"] + percent[\"P\"] + percent[\"V\"] \\\n",
        "                          + percent[\"W\"] + percent[\"Y\"],2))\n",
        "    \n",
        "    \n",
        "    obj_stats.append(round( percent[\"D\"] + percent[\"E\"] + percent[\"H\"] \\\n",
        "                          + percent[\"K\"] + percent[\"N\"] + percent[\"Q\"] \\\n",
        "                          + percent[\"R\"] + percent[\"S\"] + percent[\"T\"],2))\n",
        "\n",
        "    obj_stats.append(round( percent[\"D\"] + percent[\"E\"] + percent[\"H\"] \\\n",
        "                          + percent[\"K\"] + percent[\"R\"],2))\n",
        "    \n",
        "    obj_stats.append(round( percent[\"H\"] + percent[\"K\"] + percent[\"R\"],2))\n",
        "\n",
        "    obj_stats.append(round( percent[\"D\"] + percent[\"E\"],2))\n",
        "\n",
        "    obj_stats.append(round( percent[\"A\"],2))\n",
        "    obj_stats.append(round( percent[\"R\"],2))\n",
        "    obj_stats.append(round( percent[\"N\"],2))\n",
        "    obj_stats.append(round( percent[\"D\"],2))\n",
        "    obj_stats.append(round( percent[\"C\"],2))\n",
        "    obj_stats.append(row[\"Index\"])\n",
        "    obj_stats.append(row[\"Class\"])\n",
        "    obj_stats.append(row[\"Binary\"])\n",
        "\n",
        "\n",
        "    statistical.append(obj_stats)\n",
        "\n",
        "\n",
        "df2 = pd.DataFrame(statistical, columns=['Weight', 'Aromaticity', 'Instability', \\\n",
        "                                         'Helix', 'Turn', 'Sheet', 'Extinction', \\\n",
        "                                         'Charge10', 'Charge7', 'Charge4', \\\n",
        "                                         'Isoelectric', 'GRAVY', 'Flexibility', \\\n",
        "                                         'AverageWeight', 'Tiny', 'Small', \\\n",
        "                                         'Aliphatic', 'Aromatic', 'NonPolar', \\\n",
        "                                         'Polar', 'Charged', 'Basic', 'Acidic', \\\n",
        "                                         'Ala', 'Arg', 'Asn', 'Asp', 'Cys', \\\n",
        "                                         'Index', \"Class\", \"Binary\"])\n",
        "\n",
        "df = df.set_index(\"Index\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "5e65d590-aa24-4d25-b820-362072a62d71",
        "id": "8sEw2e3GwlaC"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Sequence Class  Binary\n",
              "Index                                                                  \n",
              "5_0     MSGDHSHNEDQIMGGSRINDSHKHKDKYKEHKHKDYKRDKEREKSK...     5       1\n",
              "5_1     MSGDHSHNEDQIMGGSRNNDSHKHKDKYKEHKHKDYKRDKEREKSK...     5       1\n",
              "5_2     MVGAAFVRPKRSPQRGDGVGRMLGGSRAVGTCGYGVNMRCLAARVN...     5       1\n",
              "5_3     VGEGCDVPCLRRRGGPYKTAAATDLSRWRLSNVEGRQSWSFVDQRD...     5       1\n",
              "5_4     MTEGTHLRRRGGPYKSDPATDLSRWRLTNDEGRQTWRYVEDQDSPD...     5       1\n",
              "...                                                   ...   ...     ...\n",
              "4_1995  MAGRVPSLLVLLLVFPSSCLAFRSPLSVFKRFKETTRPLSNECLGT...     4       1\n",
              "4_1996  MNLPPCRLWRPLTSRLGQRQPQPRAGARSCPLPARGRARPLCGRPH...     4       1\n",
              "4_1997  NVSMDTWNFSYTCLVSLWLHRFYIYSVVAFGISVWIIIQFFTTKTK...     4       1\n",
              "4_1998  MFCAKLKDLQITGDCPFSLLAPGQVPREPLGEATGSGPASTPGQPG...     4       1\n",
              "4_1999  MRVPVFYAVVLAFFCHSDSLEIQPSLYGSTRSQEAILNPSDCSART...     4       1\n",
              "\n",
              "[28000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e4a9d95-aa26-46b6-ba86-ff9c1848b434\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sequence</th>\n",
              "      <th>Class</th>\n",
              "      <th>Binary</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5_0</th>\n",
              "      <td>MSGDHSHNEDQIMGGSRINDSHKHKDKYKEHKHKDYKRDKEREKSK...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_1</th>\n",
              "      <td>MSGDHSHNEDQIMGGSRNNDSHKHKDKYKEHKHKDYKRDKEREKSK...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_2</th>\n",
              "      <td>MVGAAFVRPKRSPQRGDGVGRMLGGSRAVGTCGYGVNMRCLAARVN...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_3</th>\n",
              "      <td>VGEGCDVPCLRRRGGPYKTAAATDLSRWRLSNVEGRQSWSFVDQRD...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_4</th>\n",
              "      <td>MTEGTHLRRRGGPYKSDPATDLSRWRLTNDEGRQTWRYVEDQDSPD...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1995</th>\n",
              "      <td>MAGRVPSLLVLLLVFPSSCLAFRSPLSVFKRFKETTRPLSNECLGT...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1996</th>\n",
              "      <td>MNLPPCRLWRPLTSRLGQRQPQPRAGARSCPLPARGRARPLCGRPH...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1997</th>\n",
              "      <td>NVSMDTWNFSYTCLVSLWLHRFYIYSVVAFGISVWIIIQFFTTKTK...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1998</th>\n",
              "      <td>MFCAKLKDLQITGDCPFSLLAPGQVPREPLGEATGSGPASTPGQPG...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1999</th>\n",
              "      <td>MRVPVFYAVVLAFFCHSDSLEIQPSLYGSTRSQEAILNPSDCSART...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e4a9d95-aa26-46b6-ba86-ff9c1848b434')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e4a9d95-aa26-46b6-ba86-ff9c1848b434 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e4a9d95-aa26-46b6-ba86-ff9c1848b434');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing types of padding"
      ],
      "metadata": {
        "id": "mr4cvHBB4wX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequence(sequence, maxlen, padding='post'):\n",
        "  num_padding = maxlen - len(sequence)\n",
        "  padded_sequence = \"\"\n",
        "\n",
        "  if padding == 'post':\n",
        "    padded_sequence = sequence + \"0\" * (maxlen - len(sequence))\n",
        "\n",
        "  elif padding == 'extreme':\n",
        "    half_padding = num_padding // 2\n",
        "    padded_sequence = \"0\" * half_padding + sequence + \"0\" * (num_padding - half_padding)\n",
        "\n",
        "  elif padding == 'mid':\n",
        "    half_sequence = len(sequence) // 2\n",
        "    padded_sequence = sequence[:half_sequence] + \"0\" * num_padding + sequence[half_sequence:]\n",
        "            \n",
        "  elif padding == 'uniform':\n",
        "    for i, c in enumerate(sequence[:-1]):\n",
        "        padded_sequence += c + \"0\"\n",
        "        # If there are no more padding characters left, stop interleaving\n",
        "        if i + 1 == num_padding:\n",
        "            padded_sequence += sequence[i+1:]\n",
        "            break\n",
        "    # If there are still some padding characters left, add them to the end of the string\n",
        "    padded_sequence += \"0\" * (num_padding - len(padded_sequence) + len(sequence))\n",
        "\n",
        "  return padded_sequence"
      ],
      "metadata": {
        "id": "OuE2j9g6N06V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the function\n",
        "print(pad_sequence(\"abcd\", 10,\"post\")) \n",
        "print(pad_sequence(\"abcd\", 10,\"extreme\"))  \n",
        "print(pad_sequence(\"abcd\", 10,\"mid\"))\n",
        "print(pad_sequence(\"abcd\", 10,\"uniform\")) "
      ],
      "metadata": {
        "id": "EnYk0lgsYZl5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07768c53-60a9-4049-cf92-3897fb408e65"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abcd000000\n",
            "000abcd000\n",
            "ab000000cd\n",
            "a0b0c00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the function\n",
        "print(pad_sequence(\"abcdefg\", 10,\"post\"))  \n",
        "print(pad_sequence(\"abcdefg\", 10,\"extreme\"))  \n",
        "print(pad_sequence(\"abcdefg\", 10,\"mid\"))\n",
        "print(pad_sequence(\"abcdefg\", 10,\"uniform\"))"
      ],
      "metadata": {
        "id": "KpdVsJXKYmyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e1b843-13c0-445b-e0f9-e7b25b93391a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abcdefg000\n",
            "0abcdefg00\n",
            "abc000defg\n",
            "a0b0c0defg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First stage - perform task 1 and task 2 on the first Dataset with different types of paddings "
      ],
      "metadata": {
        "id": "5IPQWuuV9kog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['post'] = df['Sequence'].apply(lambda x: pad_sequence(x, 1000,\"post\"))"
      ],
      "metadata": {
        "id": "Q-jkrSMCAgzw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['extr'] = df['Sequence'].apply(lambda x: pad_sequence(x, 1000,\"extreme\"))\n"
      ],
      "metadata": {
        "id": "2Q9_PGd6AioK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['mid']  = df['Sequence'].apply(lambda x: pad_sequence(x, 1000,\"mid\"))\n"
      ],
      "metadata": {
        "id": "_jsG14fPAi4z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "J6uXnY7eBmUv",
        "outputId": "7ed3b2ab-60fc-415b-d81b-a3a866284a4f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Sequence Class  Binary  \\\n",
              "Index                                                                     \n",
              "5_0     MSGDHSHNEDQIMGGSRINDSHKHKDKYKEHKHKDYKRDKEREKSK...     5       1   \n",
              "5_1     MSGDHSHNEDQIMGGSRNNDSHKHKDKYKEHKHKDYKRDKEREKSK...     5       1   \n",
              "5_2     MVGAAFVRPKRSPQRGDGVGRMLGGSRAVGTCGYGVNMRCLAARVN...     5       1   \n",
              "5_3     VGEGCDVPCLRRRGGPYKTAAATDLSRWRLSNVEGRQSWSFVDQRD...     5       1   \n",
              "5_4     MTEGTHLRRRGGPYKSDPATDLSRWRLTNDEGRQTWRYVEDQDSPD...     5       1   \n",
              "...                                                   ...   ...     ...   \n",
              "4_1995  MAGRVPSLLVLLLVFPSSCLAFRSPLSVFKRFKETTRPLSNECLGT...     4       1   \n",
              "4_1996  MNLPPCRLWRPLTSRLGQRQPQPRAGARSCPLPARGRARPLCGRPH...     4       1   \n",
              "4_1997  NVSMDTWNFSYTCLVSLWLHRFYIYSVVAFGISVWIIIQFFTTKTK...     4       1   \n",
              "4_1998  MFCAKLKDLQITGDCPFSLLAPGQVPREPLGEATGSGPASTPGQPG...     4       1   \n",
              "4_1999  MRVPVFYAVVLAFFCHSDSLEIQPSLYGSTRSQEAILNPSDCSART...     4       1   \n",
              "\n",
              "                                                     post  \\\n",
              "Index                                                       \n",
              "5_0     MSGDHSHNEDQIMGGSRINDSHKHKDKYKEHKHKDYKRDKEREKSK...   \n",
              "5_1     MSGDHSHNEDQIMGGSRNNDSHKHKDKYKEHKHKDYKRDKEREKSK...   \n",
              "5_2     MVGAAFVRPKRSPQRGDGVGRMLGGSRAVGTCGYGVNMRCLAARVN...   \n",
              "5_3     VGEGCDVPCLRRRGGPYKTAAATDLSRWRLSNVEGRQSWSFVDQRD...   \n",
              "5_4     MTEGTHLRRRGGPYKSDPATDLSRWRLTNDEGRQTWRYVEDQDSPD...   \n",
              "...                                                   ...   \n",
              "4_1995  MAGRVPSLLVLLLVFPSSCLAFRSPLSVFKRFKETTRPLSNECLGT...   \n",
              "4_1996  MNLPPCRLWRPLTSRLGQRQPQPRAGARSCPLPARGRARPLCGRPH...   \n",
              "4_1997  NVSMDTWNFSYTCLVSLWLHRFYIYSVVAFGISVWIIIQFFTTKTK...   \n",
              "4_1998  MFCAKLKDLQITGDCPFSLLAPGQVPREPLGEATGSGPASTPGQPG...   \n",
              "4_1999  MRVPVFYAVVLAFFCHSDSLEIQPSLYGSTRSQEAILNPSDCSART...   \n",
              "\n",
              "                                                     extr  \\\n",
              "Index                                                       \n",
              "5_0     0000000000000000000000000000000000000000000000...   \n",
              "5_1     0000000000000000000000000000000000000000000000...   \n",
              "5_2     0000000000000000000000000000000000000000000000...   \n",
              "5_3     0000000000000000000000000000000000000000000000...   \n",
              "5_4     0000000000000000000000000000000000000000000000...   \n",
              "...                                                   ...   \n",
              "4_1995  000000000000MAGRVPSLLVLLLVFPSSCLAFRSPLSVFKRFKE...   \n",
              "4_1996  0000000000000000000000000000000000000000000000...   \n",
              "4_1997  0000000000000000000000000000000000000000000000...   \n",
              "4_1998  0000000000000000000000000000000000000000000000...   \n",
              "4_1999  0000000000000000000000000000000000000000000000...   \n",
              "\n",
              "                                                      mid  \n",
              "Index                                                      \n",
              "5_0     MSGDHSHNEDQIMGGSRINDSHKHKDKYKEHKHKDYKRDKEREKSK...  \n",
              "5_1     MSGDHSHNEDQIMGGSRNNDSHKHKDKYKEHKHKDYKRDKEREKSK...  \n",
              "5_2     MVGAAFVRPKRSPQRGDGVGRMLGGSRAVGTCGYGVNMRCLAARVN...  \n",
              "5_3     VGEGCDVPCLRRRGGPYKTAAATDLSRWRLSNVEGRQSWSFVDQRD...  \n",
              "5_4     MTEGTHLRRRGGPYKSDPATDLSRWRLTNDEGRQTWRYVEDQDSPD...  \n",
              "...                                                   ...  \n",
              "4_1995  MAGRVPSLLVLLLVFPSSCLAFRSPLSVFKRFKETTRPLSNECLGT...  \n",
              "4_1996  MNLPPCRLWRPLTSRLGQRQPQPRAGARSCPLPARGRARPLCGRPH...  \n",
              "4_1997  NVSMDTWNFSYTCLVSLWLHRFYIYSVVAFGISVWIIIQFFTTKTK...  \n",
              "4_1998  MFCAKLKDLQITGDCPFSLLAPGQVPREPLGEATGSGPASTPGQPG...  \n",
              "4_1999  MRVPVFYAVVLAFFCHSDSLEIQPSLYGSTRSQEAILNPSDCSART...  \n",
              "\n",
              "[28000 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09d4f798-b49e-496d-a18f-48ec5a7eb6d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sequence</th>\n",
              "      <th>Class</th>\n",
              "      <th>Binary</th>\n",
              "      <th>post</th>\n",
              "      <th>extr</th>\n",
              "      <th>mid</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5_0</th>\n",
              "      <td>MSGDHSHNEDQIMGGSRINDSHKHKDKYKEHKHKDYKRDKEREKSK...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>MSGDHSHNEDQIMGGSRINDSHKHKDKYKEHKHKDYKRDKEREKSK...</td>\n",
              "      <td>0000000000000000000000000000000000000000000000...</td>\n",
              "      <td>MSGDHSHNEDQIMGGSRINDSHKHKDKYKEHKHKDYKRDKEREKSK...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_1</th>\n",
              "      <td>MSGDHSHNEDQIMGGSRNNDSHKHKDKYKEHKHKDYKRDKEREKSK...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>MSGDHSHNEDQIMGGSRNNDSHKHKDKYKEHKHKDYKRDKEREKSK...</td>\n",
              "      <td>0000000000000000000000000000000000000000000000...</td>\n",
              "      <td>MSGDHSHNEDQIMGGSRNNDSHKHKDKYKEHKHKDYKRDKEREKSK...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_2</th>\n",
              "      <td>MVGAAFVRPKRSPQRGDGVGRMLGGSRAVGTCGYGVNMRCLAARVN...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>MVGAAFVRPKRSPQRGDGVGRMLGGSRAVGTCGYGVNMRCLAARVN...</td>\n",
              "      <td>0000000000000000000000000000000000000000000000...</td>\n",
              "      <td>MVGAAFVRPKRSPQRGDGVGRMLGGSRAVGTCGYGVNMRCLAARVN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_3</th>\n",
              "      <td>VGEGCDVPCLRRRGGPYKTAAATDLSRWRLSNVEGRQSWSFVDQRD...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>VGEGCDVPCLRRRGGPYKTAAATDLSRWRLSNVEGRQSWSFVDQRD...</td>\n",
              "      <td>0000000000000000000000000000000000000000000000...</td>\n",
              "      <td>VGEGCDVPCLRRRGGPYKTAAATDLSRWRLSNVEGRQSWSFVDQRD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_4</th>\n",
              "      <td>MTEGTHLRRRGGPYKSDPATDLSRWRLTNDEGRQTWRYVEDQDSPD...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>MTEGTHLRRRGGPYKSDPATDLSRWRLTNDEGRQTWRYVEDQDSPD...</td>\n",
              "      <td>0000000000000000000000000000000000000000000000...</td>\n",
              "      <td>MTEGTHLRRRGGPYKSDPATDLSRWRLTNDEGRQTWRYVEDQDSPD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1995</th>\n",
              "      <td>MAGRVPSLLVLLLVFPSSCLAFRSPLSVFKRFKETTRPLSNECLGT...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>MAGRVPSLLVLLLVFPSSCLAFRSPLSVFKRFKETTRPLSNECLGT...</td>\n",
              "      <td>000000000000MAGRVPSLLVLLLVFPSSCLAFRSPLSVFKRFKE...</td>\n",
              "      <td>MAGRVPSLLVLLLVFPSSCLAFRSPLSVFKRFKETTRPLSNECLGT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1996</th>\n",
              "      <td>MNLPPCRLWRPLTSRLGQRQPQPRAGARSCPLPARGRARPLCGRPH...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>MNLPPCRLWRPLTSRLGQRQPQPRAGARSCPLPARGRARPLCGRPH...</td>\n",
              "      <td>0000000000000000000000000000000000000000000000...</td>\n",
              "      <td>MNLPPCRLWRPLTSRLGQRQPQPRAGARSCPLPARGRARPLCGRPH...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1997</th>\n",
              "      <td>NVSMDTWNFSYTCLVSLWLHRFYIYSVVAFGISVWIIIQFFTTKTK...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>NVSMDTWNFSYTCLVSLWLHRFYIYSVVAFGISVWIIIQFFTTKTK...</td>\n",
              "      <td>0000000000000000000000000000000000000000000000...</td>\n",
              "      <td>NVSMDTWNFSYTCLVSLWLHRFYIYSVVAFGISVWIIIQFFTTKTK...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1998</th>\n",
              "      <td>MFCAKLKDLQITGDCPFSLLAPGQVPREPLGEATGSGPASTPGQPG...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>MFCAKLKDLQITGDCPFSLLAPGQVPREPLGEATGSGPASTPGQPG...</td>\n",
              "      <td>0000000000000000000000000000000000000000000000...</td>\n",
              "      <td>MFCAKLKDLQITGDCPFSLLAPGQVPREPLGEATGSGPASTPGQPG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1999</th>\n",
              "      <td>MRVPVFYAVVLAFFCHSDSLEIQPSLYGSTRSQEAILNPSDCSART...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>MRVPVFYAVVLAFFCHSDSLEIQPSLYGSTRSQEAILNPSDCSART...</td>\n",
              "      <td>0000000000000000000000000000000000000000000000...</td>\n",
              "      <td>MRVPVFYAVVLAFFCHSDSLEIQPSLYGSTRSQEAILNPSDCSART...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28000 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09d4f798-b49e-496d-a18f-48ec5a7eb6d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-09d4f798-b49e-496d-a18f-48ec5a7eb6d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-09d4f798-b49e-496d-a18f-48ec5a7eb6d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing pI encoding and scaling physico-chemical data"
      ],
      "metadata": {
        "id": "xGFy-f3ThnkZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project takes two approaches for binary and multiclass classification. \n",
        "\n",
        "The first approach is to use sequence data and represent it as an array of pIs corresponding to each aminoacid, for example:\n",
        "\n",
        "QGHEAA = [-1.35, -1.03, 0.59, -3.78, -0.98, -0.98]\n",
        "\n",
        "In the second approach, ProtParam is run on an input sequence and 28 physico-chemial parameters are extracted"
      ],
      "metadata": {
        "id": "pBi4Do4EqsDL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AA....pI........pi - 7 \\\n",
        "A  -> 6.02  -> -0.98 \\\n",
        "R  -> 10.76 ->  3.76 \\\n",
        "N  -> 5.41  -> -1.59 \\\n",
        "D  -> 2.98  -> -4.02 \\\n",
        "C  -> 5.02 ->  -1.98 \\\n",
        "E  -> 3.22  -> -3.78 \\\n",
        "Q  -> 5.65  -> -1.35 \\\n",
        "G  -> 5.97 ->  -1.03 \\\n",
        "H  -> 7.59  ->  0.59 \\\n",
        "I  -> 5.98  -> -1.02 \\\n",
        "L  -> 5.98 ->  -1.02 \\\n",
        "K  -> 9.87  ->  2.87 \\\n",
        "M  -> 5.75  -> -1.25 \\\n",
        "F  -> 5.48 ->  -1.52 \\\n",
        "P  -> 6.30  -> -0.70 \\\n",
        "S  -> 5.68  -> -1.32 \\\n",
        "T  -> 5.60  -> -1.40 \\\n",
        "W  -> 5.94  -> -1.06 \\\n",
        "Y  -> 5.66  -> -1.34 \\\n",
        "V  -> 5.97  -> -1.03 \\"
      ],
      "metadata": {
        "id": "J2g0iagFJSrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def isoelectric_encoding(sequence):\n",
        "  alphabet_dict = {'0': 0, 'A': -0.98, 'C': -1.98, 'D': -4.02, 'E': -3.78, \\\n",
        "                   'F': -1.52, 'G': -1.03, 'H': 0.59, 'I': -1.02 ,'K':2.87,\\\n",
        "                   'L': -1.02, 'M': -1.25 , 'N':-1.59 , 'P':-0.70, 'Q':-1.35, \\\n",
        "                   'R': 3.76, 'S':-1.32, 'T':-1.40, 'V':-1.03, 'W':-1.06, 'Y':-1.34}\n",
        "\n",
        "  vector = np.array([alphabet_dict[char] for char in sequence])\n",
        "  return vector"
      ],
      "metadata": {
        "id": "o7zdaaWohhSz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['post'] = df['post'].apply(lambda x: isoelectric_encoding(x))"
      ],
      "metadata": {
        "id": "-P_DJzotuzt5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['extr'] = df['extr'].apply(lambda x: isoelectric_encoding(x))\n"
      ],
      "metadata": {
        "id": "eFd1XyAzuzt6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['mid']  = df['mid'].apply(lambda x: isoelectric_encoding(x))\n"
      ],
      "metadata": {
        "id": "-xC5w0MSuzt6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "YH3w5qn2vHRP",
        "outputId": "5cab7548-4a08-4d6c-ccd3-95215a3d9d3c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Sequence Class  Binary  \\\n",
              "Index                                                                     \n",
              "5_0     MSGDHSHNEDQIMGGSRINDSHKHKDKYKEHKHKDYKRDKEREKSK...     5       1   \n",
              "5_1     MSGDHSHNEDQIMGGSRNNDSHKHKDKYKEHKHKDYKRDKEREKSK...     5       1   \n",
              "5_2     MVGAAFVRPKRSPQRGDGVGRMLGGSRAVGTCGYGVNMRCLAARVN...     5       1   \n",
              "5_3     VGEGCDVPCLRRRGGPYKTAAATDLSRWRLSNVEGRQSWSFVDQRD...     5       1   \n",
              "5_4     MTEGTHLRRRGGPYKSDPATDLSRWRLTNDEGRQTWRYVEDQDSPD...     5       1   \n",
              "...                                                   ...   ...     ...   \n",
              "4_1995  MAGRVPSLLVLLLVFPSSCLAFRSPLSVFKRFKETTRPLSNECLGT...     4       1   \n",
              "4_1996  MNLPPCRLWRPLTSRLGQRQPQPRAGARSCPLPARGRARPLCGRPH...     4       1   \n",
              "4_1997  NVSMDTWNFSYTCLVSLWLHRFYIYSVVAFGISVWIIIQFFTTKTK...     4       1   \n",
              "4_1998  MFCAKLKDLQITGDCPFSLLAPGQVPREPLGEATGSGPASTPGQPG...     4       1   \n",
              "4_1999  MRVPVFYAVVLAFFCHSDSLEIQPSLYGSTRSQEAILNPSDCSART...     4       1   \n",
              "\n",
              "                                                     post  \\\n",
              "Index                                                       \n",
              "5_0     [-1.25, -1.32, -1.03, -4.02, 0.59, -1.32, 0.59...   \n",
              "5_1     [-1.25, -1.32, -1.03, -4.02, 0.59, -1.32, 0.59...   \n",
              "5_2     [-1.25, -1.03, -1.03, -0.98, -0.98, -1.52, -1....   \n",
              "5_3     [-1.03, -1.03, -3.78, -1.03, -1.98, -4.02, -1....   \n",
              "5_4     [-1.25, -1.4, -3.78, -1.03, -1.4, 0.59, -1.02,...   \n",
              "...                                                   ...   \n",
              "4_1995  [-1.25, -0.98, -1.03, 3.76, -1.03, -0.7, -1.32...   \n",
              "4_1996  [-1.25, -1.59, -1.02, -0.7, -0.7, -1.98, 3.76,...   \n",
              "4_1997  [-1.59, -1.03, -1.32, -1.25, -4.02, -1.4, -1.0...   \n",
              "4_1998  [-1.25, -1.52, -1.98, -0.98, 2.87, -1.02, 2.87...   \n",
              "4_1999  [-1.25, 3.76, -1.03, -0.7, -1.03, -1.52, -1.34...   \n",
              "\n",
              "                                                     extr  \\\n",
              "Index                                                       \n",
              "5_0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "5_1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "5_2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "5_3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "5_4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "...                                                   ...   \n",
              "4_1995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "4_1996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "4_1997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "4_1998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "4_1999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "\n",
              "                                                      mid  \n",
              "Index                                                      \n",
              "5_0     [-1.25, -1.32, -1.03, -4.02, 0.59, -1.32, 0.59...  \n",
              "5_1     [-1.25, -1.32, -1.03, -4.02, 0.59, -1.32, 0.59...  \n",
              "5_2     [-1.25, -1.03, -1.03, -0.98, -0.98, -1.52, -1....  \n",
              "5_3     [-1.03, -1.03, -3.78, -1.03, -1.98, -4.02, -1....  \n",
              "5_4     [-1.25, -1.4, -3.78, -1.03, -1.4, 0.59, -1.02,...  \n",
              "...                                                   ...  \n",
              "4_1995  [-1.25, -0.98, -1.03, 3.76, -1.03, -0.7, -1.32...  \n",
              "4_1996  [-1.25, -1.59, -1.02, -0.7, -0.7, -1.98, 3.76,...  \n",
              "4_1997  [-1.59, -1.03, -1.32, -1.25, -4.02, -1.4, -1.0...  \n",
              "4_1998  [-1.25, -1.52, -1.98, -0.98, 2.87, -1.02, 2.87...  \n",
              "4_1999  [-1.25, 3.76, -1.03, -0.7, -1.03, -1.52, -1.34...  \n",
              "\n",
              "[28000 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b69b2ca2-2ebd-4253-b2f6-cb4a88a720ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sequence</th>\n",
              "      <th>Class</th>\n",
              "      <th>Binary</th>\n",
              "      <th>post</th>\n",
              "      <th>extr</th>\n",
              "      <th>mid</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5_0</th>\n",
              "      <td>MSGDHSHNEDQIMGGSRINDSHKHKDKYKEHKHKDYKRDKEREKSK...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>[-1.25, -1.32, -1.03, -4.02, 0.59, -1.32, 0.59...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[-1.25, -1.32, -1.03, -4.02, 0.59, -1.32, 0.59...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_1</th>\n",
              "      <td>MSGDHSHNEDQIMGGSRNNDSHKHKDKYKEHKHKDYKRDKEREKSK...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>[-1.25, -1.32, -1.03, -4.02, 0.59, -1.32, 0.59...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[-1.25, -1.32, -1.03, -4.02, 0.59, -1.32, 0.59...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_2</th>\n",
              "      <td>MVGAAFVRPKRSPQRGDGVGRMLGGSRAVGTCGYGVNMRCLAARVN...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>[-1.25, -1.03, -1.03, -0.98, -0.98, -1.52, -1....</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[-1.25, -1.03, -1.03, -0.98, -0.98, -1.52, -1....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_3</th>\n",
              "      <td>VGEGCDVPCLRRRGGPYKTAAATDLSRWRLSNVEGRQSWSFVDQRD...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>[-1.03, -1.03, -3.78, -1.03, -1.98, -4.02, -1....</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[-1.03, -1.03, -3.78, -1.03, -1.98, -4.02, -1....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_4</th>\n",
              "      <td>MTEGTHLRRRGGPYKSDPATDLSRWRLTNDEGRQTWRYVEDQDSPD...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>[-1.25, -1.4, -3.78, -1.03, -1.4, 0.59, -1.02,...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[-1.25, -1.4, -3.78, -1.03, -1.4, 0.59, -1.02,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1995</th>\n",
              "      <td>MAGRVPSLLVLLLVFPSSCLAFRSPLSVFKRFKETTRPLSNECLGT...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>[-1.25, -0.98, -1.03, 3.76, -1.03, -0.7, -1.32...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[-1.25, -0.98, -1.03, 3.76, -1.03, -0.7, -1.32...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1996</th>\n",
              "      <td>MNLPPCRLWRPLTSRLGQRQPQPRAGARSCPLPARGRARPLCGRPH...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>[-1.25, -1.59, -1.02, -0.7, -0.7, -1.98, 3.76,...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[-1.25, -1.59, -1.02, -0.7, -0.7, -1.98, 3.76,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1997</th>\n",
              "      <td>NVSMDTWNFSYTCLVSLWLHRFYIYSVVAFGISVWIIIQFFTTKTK...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>[-1.59, -1.03, -1.32, -1.25, -4.02, -1.4, -1.0...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[-1.59, -1.03, -1.32, -1.25, -4.02, -1.4, -1.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1998</th>\n",
              "      <td>MFCAKLKDLQITGDCPFSLLAPGQVPREPLGEATGSGPASTPGQPG...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>[-1.25, -1.52, -1.98, -0.98, 2.87, -1.02, 2.87...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[-1.25, -1.52, -1.98, -0.98, 2.87, -1.02, 2.87...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_1999</th>\n",
              "      <td>MRVPVFYAVVLAFFCHSDSLEIQPSLYGSTRSQEAILNPSDCSART...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>[-1.25, 3.76, -1.03, -0.7, -1.03, -1.52, -1.34...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[-1.25, 3.76, -1.03, -0.7, -1.03, -1.52, -1.34...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28000 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b69b2ca2-2ebd-4253-b2f6-cb4a88a720ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b69b2ca2-2ebd-4253-b2f6-cb4a88a720ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b69b2ca2-2ebd-4253-b2f6-cb4a88a720ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "id": "9cfXtnlz2alD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "76a395d6-56f3-4f71-9be6-4c9f512471be"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Weight  Aromaticity  Instability  Helix  Turn  Sheet  Extinction  \\\n",
              "0       89099.48         0.09        43.92   0.23  0.17   0.24      110240   \n",
              "1       84186.65         0.09        42.74   0.23  0.16   0.24      104740   \n",
              "2       71911.16         0.11        34.71   0.31  0.23   0.24      106690   \n",
              "3       80054.88         0.11        45.18   0.31  0.22   0.25      170740   \n",
              "4       82745.08         0.11        43.43   0.31  0.23   0.25      170170   \n",
              "...          ...          ...          ...    ...   ...    ...         ...   \n",
              "27995  108712.95         0.09        47.60   0.30  0.26   0.22       95230   \n",
              "27996   93586.65         0.07        35.46   0.28  0.25   0.23       98780   \n",
              "27997   82303.75         0.11        36.67   0.30  0.21   0.26      147250   \n",
              "27998   77531.96         0.08        43.55   0.31  0.23   0.25       41830   \n",
              "27999   97690.26         0.09        42.35   0.28  0.26   0.21       87210   \n",
              "\n",
              "       Charge10  Charge7  Charge4  ...  Basic  Acidic   Ala   Arg   Asn   Asp  \\\n",
              "0        -49.72    36.30   144.24  ...   0.26    0.18  0.05  0.06  0.04  0.08   \n",
              "1        -52.26    31.22   135.93  ...   0.26    0.19  0.06  0.06  0.04  0.08   \n",
              "2        -27.76    16.72    72.44  ...   0.15    0.10  0.08  0.06  0.03  0.04   \n",
              "3        -56.67    -9.42    57.32  ...   0.12    0.10  0.08  0.06  0.03  0.06   \n",
              "4        -70.45   -17.51    58.33  ...   0.12    0.12  0.07  0.05  0.03  0.06   \n",
              "...         ...      ...      ...  ...    ...     ...   ...   ...   ...   ...   \n",
              "27995    -77.11   -19.34    92.95  ...   0.14    0.13  0.05  0.05  0.04  0.06   \n",
              "27996    -41.52    14.79    96.57  ...   0.15    0.11  0.08  0.06  0.04  0.06   \n",
              "27997    -57.94     4.67    84.39  ...   0.16    0.12  0.08  0.05  0.04  0.05   \n",
              "27998    -43.59     7.98    77.52  ...   0.15    0.12  0.06  0.06  0.02  0.05   \n",
              "27999    -60.91    -3.47    80.89  ...   0.13    0.11  0.07  0.05  0.04  0.06   \n",
              "\n",
              "        Cys   Index  Class  Binary  \n",
              "0      0.01     5_0      5       1  \n",
              "1      0.01     5_1      5       1  \n",
              "2      0.01     5_2      5       1  \n",
              "3      0.04     5_3      5       1  \n",
              "4      0.03     5_4      5       1  \n",
              "...     ...     ...    ...     ...  \n",
              "27995  0.02  4_1995      4       1  \n",
              "27996  0.02  4_1996      4       1  \n",
              "27997  0.03  4_1997      4       1  \n",
              "27998  0.03  4_1998      4       1  \n",
              "27999  0.02  4_1999      4       1  \n",
              "\n",
              "[28000 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1eefc11-fd79-4685-9a77-12c3602b6ad6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weight</th>\n",
              "      <th>Aromaticity</th>\n",
              "      <th>Instability</th>\n",
              "      <th>Helix</th>\n",
              "      <th>Turn</th>\n",
              "      <th>Sheet</th>\n",
              "      <th>Extinction</th>\n",
              "      <th>Charge10</th>\n",
              "      <th>Charge7</th>\n",
              "      <th>Charge4</th>\n",
              "      <th>...</th>\n",
              "      <th>Basic</th>\n",
              "      <th>Acidic</th>\n",
              "      <th>Ala</th>\n",
              "      <th>Arg</th>\n",
              "      <th>Asn</th>\n",
              "      <th>Asp</th>\n",
              "      <th>Cys</th>\n",
              "      <th>Index</th>\n",
              "      <th>Class</th>\n",
              "      <th>Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>89099.48</td>\n",
              "      <td>0.09</td>\n",
              "      <td>43.92</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.24</td>\n",
              "      <td>110240</td>\n",
              "      <td>-49.72</td>\n",
              "      <td>36.30</td>\n",
              "      <td>144.24</td>\n",
              "      <td>...</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5_0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>84186.65</td>\n",
              "      <td>0.09</td>\n",
              "      <td>42.74</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.24</td>\n",
              "      <td>104740</td>\n",
              "      <td>-52.26</td>\n",
              "      <td>31.22</td>\n",
              "      <td>135.93</td>\n",
              "      <td>...</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5_1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>71911.16</td>\n",
              "      <td>0.11</td>\n",
              "      <td>34.71</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.24</td>\n",
              "      <td>106690</td>\n",
              "      <td>-27.76</td>\n",
              "      <td>16.72</td>\n",
              "      <td>72.44</td>\n",
              "      <td>...</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5_2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80054.88</td>\n",
              "      <td>0.11</td>\n",
              "      <td>45.18</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.25</td>\n",
              "      <td>170740</td>\n",
              "      <td>-56.67</td>\n",
              "      <td>-9.42</td>\n",
              "      <td>57.32</td>\n",
              "      <td>...</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.04</td>\n",
              "      <td>5_3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>82745.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>43.43</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.25</td>\n",
              "      <td>170170</td>\n",
              "      <td>-70.45</td>\n",
              "      <td>-17.51</td>\n",
              "      <td>58.33</td>\n",
              "      <td>...</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.03</td>\n",
              "      <td>5_4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27995</th>\n",
              "      <td>108712.95</td>\n",
              "      <td>0.09</td>\n",
              "      <td>47.60</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.22</td>\n",
              "      <td>95230</td>\n",
              "      <td>-77.11</td>\n",
              "      <td>-19.34</td>\n",
              "      <td>92.95</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.02</td>\n",
              "      <td>4_1995</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27996</th>\n",
              "      <td>93586.65</td>\n",
              "      <td>0.07</td>\n",
              "      <td>35.46</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>98780</td>\n",
              "      <td>-41.52</td>\n",
              "      <td>14.79</td>\n",
              "      <td>96.57</td>\n",
              "      <td>...</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.02</td>\n",
              "      <td>4_1996</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27997</th>\n",
              "      <td>82303.75</td>\n",
              "      <td>0.11</td>\n",
              "      <td>36.67</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.26</td>\n",
              "      <td>147250</td>\n",
              "      <td>-57.94</td>\n",
              "      <td>4.67</td>\n",
              "      <td>84.39</td>\n",
              "      <td>...</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.03</td>\n",
              "      <td>4_1997</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27998</th>\n",
              "      <td>77531.96</td>\n",
              "      <td>0.08</td>\n",
              "      <td>43.55</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.25</td>\n",
              "      <td>41830</td>\n",
              "      <td>-43.59</td>\n",
              "      <td>7.98</td>\n",
              "      <td>77.52</td>\n",
              "      <td>...</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.03</td>\n",
              "      <td>4_1998</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27999</th>\n",
              "      <td>97690.26</td>\n",
              "      <td>0.09</td>\n",
              "      <td>42.35</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.21</td>\n",
              "      <td>87210</td>\n",
              "      <td>-60.91</td>\n",
              "      <td>-3.47</td>\n",
              "      <td>80.89</td>\n",
              "      <td>...</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.02</td>\n",
              "      <td>4_1999</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28000 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1eefc11-fd79-4685-9a77-12c3602b6ad6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f1eefc11-fd79-4685-9a77-12c3602b6ad6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f1eefc11-fd79-4685-9a77-12c3602b6ad6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scale the table with physicochemical parameters"
      ],
      "metadata": {
        "id": "0Ifx7rJBJJKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "data_subset = df2.iloc[:,0:28]\n",
        "scaled_subset = scaler.fit_transform(data_subset)\n",
        "scaled_df = pd.DataFrame(scaled_subset,columns=data_subset.columns)\n",
        "scaled_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "YTIY5ckZyRGq",
        "outputId": "8f3b8fae-0230-4b82-aab2-1e3b66ee61ff"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Weight  Aromaticity  Instability     Helix      Turn     Sheet  \\\n",
              "0      0.122565     0.428075    -0.164488 -1.582710 -1.965963 -0.549310   \n",
              "1     -0.261003     0.428075    -0.299549 -1.582710 -2.255166 -0.549310   \n",
              "2     -1.219409     1.423019    -1.218652  0.467397 -0.230743 -0.549310   \n",
              "3     -0.583590     1.423019    -0.020270  0.467397 -0.519946 -0.227457   \n",
              "4     -0.373554     1.423019    -0.220573  0.467397 -0.230743 -0.227457   \n",
              "...         ...          ...          ...       ...       ...       ...   \n",
              "27995  1.653882     0.428075     0.256720  0.211133  0.636867 -1.193014   \n",
              "27996  0.472899    -0.566870    -1.132808 -0.301393  0.347664 -0.871162   \n",
              "27997 -0.408010     1.423019    -0.994313  0.211133 -0.809150  0.094395   \n",
              "27998 -0.780567    -0.069397    -0.206838  0.467397 -0.230743 -0.227457   \n",
              "27999  0.793288     0.428075    -0.344188 -0.301393  0.636867 -1.514866   \n",
              "\n",
              "       Extinction  Charge10   Charge7   Charge4  ...  NonPolar     Polar  \\\n",
              "0        0.717823  0.379109  2.309880  3.596773  ... -2.885270  2.885163   \n",
              "1        0.549156  0.254213  2.023867  3.166481  ... -3.322498  3.322370   \n",
              "2        0.608956  1.458918  1.207491 -0.121035  ...  0.393943 -0.393884   \n",
              "3        2.573166  0.037367 -0.264239 -0.903950  ...  0.831171 -0.831090   \n",
              "4        2.555686 -0.640218 -0.719721 -0.851652  ...  0.612557 -0.612487   \n",
              "...           ...       ...       ...       ...  ...       ...       ...   \n",
              "27995    0.257514 -0.967701 -0.822753  0.940974  ... -0.043286  0.043322   \n",
              "27996    0.366381  0.782317  1.098828  1.128418  ...  0.393943 -0.393884   \n",
              "27997    1.852803 -0.025081  0.529054  0.497736  ... -0.043286  0.043322   \n",
              "27998   -1.380095  0.680531  0.715413  0.142007  ...  0.393943 -0.393884   \n",
              "27999    0.011566 -0.171121  0.070757  0.316506  ... -0.261900  0.261926   \n",
              "\n",
              "        Charged     Basic    Acidic       Ala       Arg       Asn       Asp  \\\n",
              "0      4.301177  4.936276  2.432950 -1.062543  0.415398  0.136213  2.265319   \n",
              "1      4.301177  4.936276  2.836802 -0.512877  0.415398  0.136213  2.265319   \n",
              "2     -0.179154  0.494987 -0.797868  0.586454  0.415398 -0.704607 -0.946964   \n",
              "3     -0.886575 -0.716273 -0.797868  0.586454  0.415398 -0.704607  0.659178   \n",
              "4     -0.414961 -0.716273  0.009837  0.036788 -0.292523 -0.704607  0.659178   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "27995  0.292459  0.091234  0.413689 -1.062543 -0.292523  0.136213  0.659178   \n",
              "27996  0.056653  0.494987 -0.394016  0.586454  0.415398  0.136213  0.659178   \n",
              "27997  0.528266  0.898741  0.009837  0.586454 -0.292523  0.136213 -0.143893   \n",
              "27998  0.292459  0.494987  0.009837 -0.512877  0.415398 -1.545427 -0.143893   \n",
              "27999 -0.179154 -0.312520 -0.394016  0.036788 -0.292523  0.136213  0.659178   \n",
              "\n",
              "            Cys  \n",
              "0     -1.004342  \n",
              "1     -1.004342  \n",
              "2     -1.004342  \n",
              "3      1.447409  \n",
              "4      0.630158  \n",
              "...         ...  \n",
              "27995 -0.187092  \n",
              "27996 -0.187092  \n",
              "27997  0.630158  \n",
              "27998  0.630158  \n",
              "27999 -0.187092  \n",
              "\n",
              "[28000 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0885796-3e12-43b4-a03e-27fbfc491614\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weight</th>\n",
              "      <th>Aromaticity</th>\n",
              "      <th>Instability</th>\n",
              "      <th>Helix</th>\n",
              "      <th>Turn</th>\n",
              "      <th>Sheet</th>\n",
              "      <th>Extinction</th>\n",
              "      <th>Charge10</th>\n",
              "      <th>Charge7</th>\n",
              "      <th>Charge4</th>\n",
              "      <th>...</th>\n",
              "      <th>NonPolar</th>\n",
              "      <th>Polar</th>\n",
              "      <th>Charged</th>\n",
              "      <th>Basic</th>\n",
              "      <th>Acidic</th>\n",
              "      <th>Ala</th>\n",
              "      <th>Arg</th>\n",
              "      <th>Asn</th>\n",
              "      <th>Asp</th>\n",
              "      <th>Cys</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.122565</td>\n",
              "      <td>0.428075</td>\n",
              "      <td>-0.164488</td>\n",
              "      <td>-1.582710</td>\n",
              "      <td>-1.965963</td>\n",
              "      <td>-0.549310</td>\n",
              "      <td>0.717823</td>\n",
              "      <td>0.379109</td>\n",
              "      <td>2.309880</td>\n",
              "      <td>3.596773</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.885270</td>\n",
              "      <td>2.885163</td>\n",
              "      <td>4.301177</td>\n",
              "      <td>4.936276</td>\n",
              "      <td>2.432950</td>\n",
              "      <td>-1.062543</td>\n",
              "      <td>0.415398</td>\n",
              "      <td>0.136213</td>\n",
              "      <td>2.265319</td>\n",
              "      <td>-1.004342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.261003</td>\n",
              "      <td>0.428075</td>\n",
              "      <td>-0.299549</td>\n",
              "      <td>-1.582710</td>\n",
              "      <td>-2.255166</td>\n",
              "      <td>-0.549310</td>\n",
              "      <td>0.549156</td>\n",
              "      <td>0.254213</td>\n",
              "      <td>2.023867</td>\n",
              "      <td>3.166481</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.322498</td>\n",
              "      <td>3.322370</td>\n",
              "      <td>4.301177</td>\n",
              "      <td>4.936276</td>\n",
              "      <td>2.836802</td>\n",
              "      <td>-0.512877</td>\n",
              "      <td>0.415398</td>\n",
              "      <td>0.136213</td>\n",
              "      <td>2.265319</td>\n",
              "      <td>-1.004342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.219409</td>\n",
              "      <td>1.423019</td>\n",
              "      <td>-1.218652</td>\n",
              "      <td>0.467397</td>\n",
              "      <td>-0.230743</td>\n",
              "      <td>-0.549310</td>\n",
              "      <td>0.608956</td>\n",
              "      <td>1.458918</td>\n",
              "      <td>1.207491</td>\n",
              "      <td>-0.121035</td>\n",
              "      <td>...</td>\n",
              "      <td>0.393943</td>\n",
              "      <td>-0.393884</td>\n",
              "      <td>-0.179154</td>\n",
              "      <td>0.494987</td>\n",
              "      <td>-0.797868</td>\n",
              "      <td>0.586454</td>\n",
              "      <td>0.415398</td>\n",
              "      <td>-0.704607</td>\n",
              "      <td>-0.946964</td>\n",
              "      <td>-1.004342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.583590</td>\n",
              "      <td>1.423019</td>\n",
              "      <td>-0.020270</td>\n",
              "      <td>0.467397</td>\n",
              "      <td>-0.519946</td>\n",
              "      <td>-0.227457</td>\n",
              "      <td>2.573166</td>\n",
              "      <td>0.037367</td>\n",
              "      <td>-0.264239</td>\n",
              "      <td>-0.903950</td>\n",
              "      <td>...</td>\n",
              "      <td>0.831171</td>\n",
              "      <td>-0.831090</td>\n",
              "      <td>-0.886575</td>\n",
              "      <td>-0.716273</td>\n",
              "      <td>-0.797868</td>\n",
              "      <td>0.586454</td>\n",
              "      <td>0.415398</td>\n",
              "      <td>-0.704607</td>\n",
              "      <td>0.659178</td>\n",
              "      <td>1.447409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.373554</td>\n",
              "      <td>1.423019</td>\n",
              "      <td>-0.220573</td>\n",
              "      <td>0.467397</td>\n",
              "      <td>-0.230743</td>\n",
              "      <td>-0.227457</td>\n",
              "      <td>2.555686</td>\n",
              "      <td>-0.640218</td>\n",
              "      <td>-0.719721</td>\n",
              "      <td>-0.851652</td>\n",
              "      <td>...</td>\n",
              "      <td>0.612557</td>\n",
              "      <td>-0.612487</td>\n",
              "      <td>-0.414961</td>\n",
              "      <td>-0.716273</td>\n",
              "      <td>0.009837</td>\n",
              "      <td>0.036788</td>\n",
              "      <td>-0.292523</td>\n",
              "      <td>-0.704607</td>\n",
              "      <td>0.659178</td>\n",
              "      <td>0.630158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27995</th>\n",
              "      <td>1.653882</td>\n",
              "      <td>0.428075</td>\n",
              "      <td>0.256720</td>\n",
              "      <td>0.211133</td>\n",
              "      <td>0.636867</td>\n",
              "      <td>-1.193014</td>\n",
              "      <td>0.257514</td>\n",
              "      <td>-0.967701</td>\n",
              "      <td>-0.822753</td>\n",
              "      <td>0.940974</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.043286</td>\n",
              "      <td>0.043322</td>\n",
              "      <td>0.292459</td>\n",
              "      <td>0.091234</td>\n",
              "      <td>0.413689</td>\n",
              "      <td>-1.062543</td>\n",
              "      <td>-0.292523</td>\n",
              "      <td>0.136213</td>\n",
              "      <td>0.659178</td>\n",
              "      <td>-0.187092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27996</th>\n",
              "      <td>0.472899</td>\n",
              "      <td>-0.566870</td>\n",
              "      <td>-1.132808</td>\n",
              "      <td>-0.301393</td>\n",
              "      <td>0.347664</td>\n",
              "      <td>-0.871162</td>\n",
              "      <td>0.366381</td>\n",
              "      <td>0.782317</td>\n",
              "      <td>1.098828</td>\n",
              "      <td>1.128418</td>\n",
              "      <td>...</td>\n",
              "      <td>0.393943</td>\n",
              "      <td>-0.393884</td>\n",
              "      <td>0.056653</td>\n",
              "      <td>0.494987</td>\n",
              "      <td>-0.394016</td>\n",
              "      <td>0.586454</td>\n",
              "      <td>0.415398</td>\n",
              "      <td>0.136213</td>\n",
              "      <td>0.659178</td>\n",
              "      <td>-0.187092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27997</th>\n",
              "      <td>-0.408010</td>\n",
              "      <td>1.423019</td>\n",
              "      <td>-0.994313</td>\n",
              "      <td>0.211133</td>\n",
              "      <td>-0.809150</td>\n",
              "      <td>0.094395</td>\n",
              "      <td>1.852803</td>\n",
              "      <td>-0.025081</td>\n",
              "      <td>0.529054</td>\n",
              "      <td>0.497736</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.043286</td>\n",
              "      <td>0.043322</td>\n",
              "      <td>0.528266</td>\n",
              "      <td>0.898741</td>\n",
              "      <td>0.009837</td>\n",
              "      <td>0.586454</td>\n",
              "      <td>-0.292523</td>\n",
              "      <td>0.136213</td>\n",
              "      <td>-0.143893</td>\n",
              "      <td>0.630158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27998</th>\n",
              "      <td>-0.780567</td>\n",
              "      <td>-0.069397</td>\n",
              "      <td>-0.206838</td>\n",
              "      <td>0.467397</td>\n",
              "      <td>-0.230743</td>\n",
              "      <td>-0.227457</td>\n",
              "      <td>-1.380095</td>\n",
              "      <td>0.680531</td>\n",
              "      <td>0.715413</td>\n",
              "      <td>0.142007</td>\n",
              "      <td>...</td>\n",
              "      <td>0.393943</td>\n",
              "      <td>-0.393884</td>\n",
              "      <td>0.292459</td>\n",
              "      <td>0.494987</td>\n",
              "      <td>0.009837</td>\n",
              "      <td>-0.512877</td>\n",
              "      <td>0.415398</td>\n",
              "      <td>-1.545427</td>\n",
              "      <td>-0.143893</td>\n",
              "      <td>0.630158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27999</th>\n",
              "      <td>0.793288</td>\n",
              "      <td>0.428075</td>\n",
              "      <td>-0.344188</td>\n",
              "      <td>-0.301393</td>\n",
              "      <td>0.636867</td>\n",
              "      <td>-1.514866</td>\n",
              "      <td>0.011566</td>\n",
              "      <td>-0.171121</td>\n",
              "      <td>0.070757</td>\n",
              "      <td>0.316506</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.261900</td>\n",
              "      <td>0.261926</td>\n",
              "      <td>-0.179154</td>\n",
              "      <td>-0.312520</td>\n",
              "      <td>-0.394016</td>\n",
              "      <td>0.036788</td>\n",
              "      <td>-0.292523</td>\n",
              "      <td>0.136213</td>\n",
              "      <td>0.659178</td>\n",
              "      <td>-0.187092</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28000 rows × 28 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0885796-3e12-43b4-a03e-27fbfc491614')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e0885796-3e12-43b4-a03e-27fbfc491614 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e0885796-3e12-43b4-a03e-27fbfc491614');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The project experiments on three model architectures, with no convolution, with one convolutional layer and with three convolutional layers (implemented from scratch in Keras)"
      ],
      "metadata": {
        "id": "G4iG6F9LrfNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Architecture #1 - no convolution"
      ],
      "metadata": {
        "id": "j93p3J7iyv1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def noConv(input_size, hidden_size, num_classes):\n",
        "    inputs = Input(shape=(input_size,))\n",
        "    fc1 = Dense(hidden_size, activation='relu')(inputs)\n",
        "    dropout1 = Dropout(0.5)(fc1)\n",
        "    fc2 = Dense(hidden_size, activation='relu')(dropout1)\n",
        "    dropout2 = Dropout(0.25)(fc2)\n",
        "    fc3 = Dense(num_classes, activation='sigmoid')(dropout2)\n",
        "    model = Model(inputs, fc3)\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "a6bvv7LYyvR8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Architecture #2 - 1 convolutional layer"
      ],
      "metadata": {
        "id": "GvIXIXIBy33v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def oneCNN(input_size, num_classes):\n",
        "\n",
        "    inputs = Input(shape=(input_size, 1))\n",
        "    conv_layer1 = Conv1D(32, 3, activation='relu', input_shape=(input_size, 1))(inputs)\n",
        "    pooling_layer1 = MaxPooling1D(pool_size=2)(conv_layer1)\n",
        "    dropout1 = Dropout(0.5)(pooling_layer1)\n",
        "    flatten = Flatten()(conv_layer1)\n",
        "    fc1 = Dense(16, activation='relu')(flatten)\n",
        "    fc2 = Dense(8, activation='relu')(fc1)\n",
        "    fc3 = Dense(num_classes, activation='sigmoid')(fc2)\n",
        "    \n",
        "    model = Model(inputs, fc3)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "7dzlb1Ijy33w"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Architecture #3 - stack of 5 convolutional layers"
      ],
      "metadata": {
        "id": "290ZN35zy4HV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stackedCNN(input_size, num_classes):\n",
        "    inputs = Input(shape=(input_size, 1))\n",
        "    conv_layer1 = Conv1D(32, 2, activation='relu', input_shape=(input_size, 1))(inputs)\n",
        "    pooling_layer1 = MaxPooling1D(pool_size=2)(conv_layer1)\n",
        "    conv_layer2 = Conv1D(256, 2, activation='relu')(pooling_layer1)\n",
        "    dropout1 = Dropout(0.5)(conv_layer2)\n",
        "    conv_layer3 = Conv1D(128, 2, activation='relu')(dropout1)\n",
        "    pooling_layer2 = MaxPooling1D(pool_size=2)(conv_layer3)\n",
        "    conv_layer4 = Conv1D(64, 2, activation='relu')(pooling_layer2)\n",
        "    dropout2 = Dropout(0.25)(conv_layer4)\n",
        "    conv_layer5 = Conv1D(32, 2, activation='relu')(dropout2)\n",
        "    flatten = Flatten()(conv_layer5)\n",
        "    fc1 = Dense(16, activation='relu')(flatten)\n",
        "    fc2 = Dense(8, activation='relu')(fc1)\n",
        "    fc3 = Dense(num_classes, activation='sigmoid')(fc2)\n",
        "    \n",
        "    model = Model(inputs, fc3)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "iaYO9poBy4HV"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test different kinds of paddings on dataset 1\n"
      ],
      "metadata": {
        "id": "lU1lliPcybu2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a first stage of the project, post, extreme and mid padding were used in task1 - binary classification and in task2 - multiclass classification on dataset 1."
      ],
      "metadata": {
        "id": "aNzhxN0osFDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1 - binary classification 14000 enzymes and 14000 non-enzymes"
      ],
      "metadata": {
        "id": "jlzFisOFrVIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hiperparameters - batch_size and epochs were manually tested, 64 and 45 were chosen. "
      ],
      "metadata": {
        "id": "dT8xtj83UhfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "epochs = 45"
      ],
      "metadata": {
        "id": "F195jkQzZTkT"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for padding in [\"post\", \"extr\", \"mid\"]:\n",
        "  X = df[padding].values\n",
        "  X = X.tolist()\n",
        "  X = np.stack(X)\n",
        "  y = df2['Binary'].values\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "  X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "  y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
        "  X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
        "  y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
        "\n",
        "  model = noConv(1000, 64, 1)\n",
        "  model.compile(optimizer=Adam(), loss = binary_crossentropy, metrics=[\"accuracy\"])\n",
        "  model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, verbose=1)\n",
        "  _, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "  print(\"Test accuracy:\", test_acc)\n",
        "  model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuCr6RdRPMPU",
        "outputId": "2dbac9df-445a-47c8-ee63-343139115f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6924 - accuracy: 0.5600\n",
            "Epoch 2/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6304 - accuracy: 0.6165\n",
            "Epoch 3/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5942 - accuracy: 0.6554\n",
            "Epoch 4/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5746 - accuracy: 0.6749\n",
            "Epoch 5/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5531 - accuracy: 0.6908\n",
            "Epoch 6/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5388 - accuracy: 0.7040\n",
            "Epoch 7/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5195 - accuracy: 0.7142\n",
            "Epoch 8/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5044 - accuracy: 0.7252\n",
            "Epoch 9/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4948 - accuracy: 0.7331\n",
            "Epoch 10/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4831 - accuracy: 0.7425\n",
            "Epoch 11/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4774 - accuracy: 0.7492\n",
            "Epoch 12/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4697 - accuracy: 0.7532\n",
            "Epoch 13/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4588 - accuracy: 0.7580\n",
            "Epoch 14/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4581 - accuracy: 0.7583\n",
            "Epoch 15/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4542 - accuracy: 0.7624\n",
            "Epoch 16/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4378 - accuracy: 0.7711\n",
            "Epoch 17/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4369 - accuracy: 0.7712\n",
            "Epoch 18/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4348 - accuracy: 0.7743\n",
            "Epoch 19/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4291 - accuracy: 0.7774\n",
            "Epoch 20/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4227 - accuracy: 0.7803\n",
            "Epoch 21/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4178 - accuracy: 0.7830\n",
            "Epoch 22/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4146 - accuracy: 0.7829\n",
            "Epoch 23/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4138 - accuracy: 0.7857\n",
            "Epoch 24/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4116 - accuracy: 0.7870\n",
            "Epoch 25/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4017 - accuracy: 0.7907\n",
            "Epoch 26/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4040 - accuracy: 0.7902\n",
            "Epoch 27/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4016 - accuracy: 0.7902\n",
            "Epoch 28/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3995 - accuracy: 0.7921\n",
            "Epoch 29/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3952 - accuracy: 0.7955\n",
            "Epoch 30/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3935 - accuracy: 0.7938\n",
            "Epoch 31/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3899 - accuracy: 0.7981\n",
            "Epoch 32/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3862 - accuracy: 0.8011\n",
            "Epoch 33/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3883 - accuracy: 0.8000\n",
            "Epoch 34/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3843 - accuracy: 0.7999\n",
            "Epoch 35/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3893 - accuracy: 0.7975\n",
            "Epoch 36/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3786 - accuracy: 0.8033\n",
            "Epoch 37/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3802 - accuracy: 0.8010\n",
            "Epoch 38/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3756 - accuracy: 0.8054\n",
            "Epoch 39/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3757 - accuracy: 0.8049\n",
            "Epoch 40/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3776 - accuracy: 0.8040\n",
            "Epoch 41/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3736 - accuracy: 0.8048\n",
            "Epoch 42/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3691 - accuracy: 0.8089\n",
            "Epoch 43/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3714 - accuracy: 0.8079\n",
            "Epoch 44/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3669 - accuracy: 0.8093\n",
            "Epoch 45/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3673 - accuracy: 0.8092\n",
            "Test accuracy: 0.6650000214576721\n",
            "Model: \"model_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_43 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_126 (Dense)           (None, 64)                64064     \n",
            "                                                                 \n",
            " dropout_84 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_127 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_85 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_128 (Dense)           (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,289\n",
            "Trainable params: 68,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.7104 - accuracy: 0.5281\n",
            "Epoch 2/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6501 - accuracy: 0.5863\n",
            "Epoch 3/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6249 - accuracy: 0.6110\n",
            "Epoch 4/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6029 - accuracy: 0.6328\n",
            "Epoch 5/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5838 - accuracy: 0.6450\n",
            "Epoch 6/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5682 - accuracy: 0.6592\n",
            "Epoch 7/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5543 - accuracy: 0.6746\n",
            "Epoch 8/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5416 - accuracy: 0.6796\n",
            "Epoch 9/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5271 - accuracy: 0.6904\n",
            "Epoch 10/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5178 - accuracy: 0.6949\n",
            "Epoch 11/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5045 - accuracy: 0.7064\n",
            "Epoch 12/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4981 - accuracy: 0.7090\n",
            "Epoch 13/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4910 - accuracy: 0.7136\n",
            "Epoch 14/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4809 - accuracy: 0.7215\n",
            "Epoch 15/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4756 - accuracy: 0.7242\n",
            "Epoch 16/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4677 - accuracy: 0.7264\n",
            "Epoch 17/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4580 - accuracy: 0.7347\n",
            "Epoch 18/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4551 - accuracy: 0.7325\n",
            "Epoch 19/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4460 - accuracy: 0.7412\n",
            "Epoch 20/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4437 - accuracy: 0.7420\n",
            "Epoch 21/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4383 - accuracy: 0.7446\n",
            "Epoch 22/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4324 - accuracy: 0.7443\n",
            "Epoch 23/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4279 - accuracy: 0.7469\n",
            "Epoch 24/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4278 - accuracy: 0.7500\n",
            "Epoch 25/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4202 - accuracy: 0.7521\n",
            "Epoch 26/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4214 - accuracy: 0.7497\n",
            "Epoch 27/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4210 - accuracy: 0.7515\n",
            "Epoch 28/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4106 - accuracy: 0.7560\n",
            "Epoch 29/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4111 - accuracy: 0.7568\n",
            "Epoch 30/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4014 - accuracy: 0.7642\n",
            "Epoch 31/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4029 - accuracy: 0.7617\n",
            "Epoch 32/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3964 - accuracy: 0.7646\n",
            "Epoch 33/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4017 - accuracy: 0.7613\n",
            "Epoch 34/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3992 - accuracy: 0.7629\n",
            "Epoch 35/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3911 - accuracy: 0.7669\n",
            "Epoch 36/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3922 - accuracy: 0.7673\n",
            "Epoch 37/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3911 - accuracy: 0.7664\n",
            "Epoch 38/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3883 - accuracy: 0.7683\n",
            "Epoch 39/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3823 - accuracy: 0.7735\n",
            "Epoch 40/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3842 - accuracy: 0.7718\n",
            "Epoch 41/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3766 - accuracy: 0.7778\n",
            "Epoch 42/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3803 - accuracy: 0.7727\n",
            "Epoch 43/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3787 - accuracy: 0.7737\n",
            "Epoch 44/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3770 - accuracy: 0.7756\n",
            "Epoch 45/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3788 - accuracy: 0.7740\n",
            "Test accuracy: 0.6460714340209961\n",
            "Model: \"model_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_44 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_129 (Dense)           (None, 64)                64064     \n",
            "                                                                 \n",
            " dropout_86 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_130 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_87 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_131 (Dense)           (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,289\n",
            "Trainable params: 68,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/45\n",
            "350/350 [==============================] - 2s 3ms/step - loss: 0.6595 - accuracy: 0.6086\n",
            "Epoch 2/45\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5631 - accuracy: 0.6902\n",
            "Epoch 3/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5208 - accuracy: 0.7192\n",
            "Epoch 4/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4903 - accuracy: 0.7402\n",
            "Epoch 5/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4791 - accuracy: 0.7497\n",
            "Epoch 6/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4549 - accuracy: 0.7617\n",
            "Epoch 7/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4479 - accuracy: 0.7671\n",
            "Epoch 8/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4366 - accuracy: 0.7728\n",
            "Epoch 9/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4247 - accuracy: 0.7773\n",
            "Epoch 10/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4133 - accuracy: 0.7864\n",
            "Epoch 11/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4060 - accuracy: 0.7897\n",
            "Epoch 12/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3975 - accuracy: 0.7950\n",
            "Epoch 13/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3893 - accuracy: 0.7991\n",
            "Epoch 14/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3856 - accuracy: 0.8000\n",
            "Epoch 15/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3809 - accuracy: 0.8034\n",
            "Epoch 16/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3733 - accuracy: 0.8073\n",
            "Epoch 17/45\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3702 - accuracy: 0.8080\n",
            "Epoch 18/45\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3634 - accuracy: 0.8113\n",
            "Epoch 19/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3621 - accuracy: 0.8112\n",
            "Epoch 20/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3553 - accuracy: 0.8147\n",
            "Epoch 21/45\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3566 - accuracy: 0.8112\n",
            "Epoch 22/45\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3502 - accuracy: 0.8170\n",
            "Epoch 23/45\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3488 - accuracy: 0.8154\n",
            "Epoch 24/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3469 - accuracy: 0.8151\n",
            "Epoch 25/45\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3407 - accuracy: 0.8201\n",
            "Epoch 26/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3383 - accuracy: 0.8233\n",
            "Epoch 27/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3402 - accuracy: 0.8214\n",
            "Epoch 28/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3357 - accuracy: 0.8232\n",
            "Epoch 29/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3303 - accuracy: 0.8245\n",
            "Epoch 30/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3286 - accuracy: 0.8248\n",
            "Epoch 31/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3257 - accuracy: 0.8257\n",
            "Epoch 32/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3283 - accuracy: 0.8246\n",
            "Epoch 33/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3268 - accuracy: 0.8248\n",
            "Epoch 34/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3195 - accuracy: 0.8283\n",
            "Epoch 35/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3227 - accuracy: 0.8287\n",
            "Epoch 36/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3173 - accuracy: 0.8284\n",
            "Epoch 37/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3143 - accuracy: 0.8309\n",
            "Epoch 38/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3165 - accuracy: 0.8292\n",
            "Epoch 39/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3151 - accuracy: 0.8311\n",
            "Epoch 40/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3112 - accuracy: 0.8310\n",
            "Epoch 41/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3130 - accuracy: 0.8311\n",
            "Epoch 42/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3096 - accuracy: 0.8300\n",
            "Epoch 43/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3072 - accuracy: 0.8329\n",
            "Epoch 44/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3097 - accuracy: 0.8288\n",
            "Epoch 45/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3029 - accuracy: 0.8348\n",
            "Test accuracy: 0.7033928632736206\n",
            "Model: \"model_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_45 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_132 (Dense)           (None, 64)                64064     \n",
            "                                                                 \n",
            " dropout_88 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_133 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_89 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_134 (Dense)           (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,289\n",
            "Trainable params: 68,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The paddings got the following accuracy:\n",
        "\n",
        "\n",
        "\n",
        "1.   post - 60.5%\n",
        "2.   extreme - 64.6%\n",
        "3.   mid - 70.3%\n",
        "\n"
      ],
      "metadata": {
        "id": "pAMBZSRtriIk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing out task 2 - 14000 enzymes in 7 classes per 2000 observations (multiclass classification)"
      ],
      "metadata": {
        "id": "KPsUFfFsr51-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df[df[\"Binary\"] != 0]\n",
        "df4 = df2[df2[\"Binary\"] != 0]\n",
        "data_subset = df4.iloc[:,0:28]\n",
        "scaled_subset = scaler.fit_transform(data_subset)\n",
        "scaled_df2 = pd.DataFrame(scaled_subset,columns=data_subset.columns)\n",
        "scaled_df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "CBoSaEwnjpSF",
        "outputId": "4819e350-2a50-42dd-8ab9-c22a29a3d99d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Weight  Aromaticity  Instability     Helix      Turn     Sheet  \\\n",
              "0      0.019064     0.340273     0.184694 -2.247021 -2.365072 -0.641198   \n",
              "1     -0.354484     0.340273     0.020202 -2.247021 -2.756400 -0.641198   \n",
              "2     -1.287853     1.426167    -1.099181  0.267505 -0.017107 -0.641198   \n",
              "3     -0.668644     1.426167     0.360338  0.267505 -0.408434 -0.253684   \n",
              "4     -0.464094     1.426167     0.116388  0.267505 -0.017107 -0.253684   \n",
              "...         ...          ...          ...       ...       ...       ...   \n",
              "13995  1.510377     0.340273     0.697687 -0.046811  1.156876 -1.416227   \n",
              "13996  0.360246    -0.745621    -0.994631 -0.675442  0.765549 -1.028713   \n",
              "13997 -0.497651     1.426167    -0.825957 -0.046811 -0.799762  0.133831   \n",
              "13998 -0.860474    -0.202674     0.133116  0.267505 -0.017107 -0.253684   \n",
              "13999  0.672265     0.340273    -0.034164 -0.675442  1.156876 -1.803742   \n",
              "\n",
              "       Extinction  Charge10   Charge7   Charge4  ...  NonPolar     Polar  \\\n",
              "0        0.684356  0.387380  2.649837  3.546482  ... -3.561624  3.561163   \n",
              "1        0.504808  0.227563  2.296024  3.107736  ... -4.062218  4.061678   \n",
              "2        0.568465  1.769109  1.286124 -0.244375  ...  0.192836 -0.192698   \n",
              "3        2.659384 -0.049915 -0.534483 -1.042672  ...  0.693431 -0.693213   \n",
              "4        2.640776 -0.916956 -1.097938 -0.989347  ...  0.443134 -0.442956   \n",
              "...           ...       ...       ...       ...  ...       ...       ...   \n",
              "13995    0.194353 -1.336005 -1.225394  0.838501  ... -0.307758  0.307817   \n",
              "13996    0.310243  0.903326  1.151702  1.029628  ...  0.192836 -0.192698   \n",
              "13997    1.892551 -0.129824  0.446862  0.386555  ... -0.307758  0.307817   \n",
              "13998   -1.548895  0.773081  0.677398  0.023837  ...  0.192836 -0.192698   \n",
              "13999   -0.067461 -0.316697 -0.120075  0.201764  ... -0.558056  0.558074   \n",
              "\n",
              "        Charged     Basic    Acidic       Ala       Arg       Asn       Asp  \\\n",
              "0      4.386968  4.699078  2.991882 -1.275096  0.502404  0.274225  2.582006   \n",
              "1      4.386968  4.699078  3.468611 -0.642608  0.502404  0.274225  2.582006   \n",
              "2     -0.146362  0.436173 -0.821949  0.622368  0.502404 -0.700179 -1.076892   \n",
              "3     -0.862151 -0.726438 -0.821949  0.622368  0.502404 -0.700179  0.752557   \n",
              "4     -0.384958 -0.726438  0.131509 -0.010120 -0.247213 -0.700179  0.752557   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "13995  0.330831  0.048636  0.608238 -1.275096 -0.247213  0.274225  0.752557   \n",
              "13996  0.092235  0.436173 -0.345220  0.622368  0.502404  0.274225  0.752557   \n",
              "13997  0.569427  0.823710  0.131509  0.622368 -0.247213  0.274225 -0.162168   \n",
              "13998  0.330831  0.436173  0.131509 -0.642608  0.502404 -1.674583 -0.162168   \n",
              "13999 -0.146362 -0.338901 -0.345220 -0.010120 -0.247213  0.274225  0.752557   \n",
              "\n",
              "            Cys  \n",
              "0     -1.256611  \n",
              "1     -1.256611  \n",
              "2     -1.256611  \n",
              "3      1.934685  \n",
              "4      0.870920  \n",
              "...         ...  \n",
              "13995 -0.192845  \n",
              "13996 -0.192845  \n",
              "13997  0.870920  \n",
              "13998  0.870920  \n",
              "13999 -0.192845  \n",
              "\n",
              "[14000 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba1dca1d-d258-40ae-86aa-eadc3fc580de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weight</th>\n",
              "      <th>Aromaticity</th>\n",
              "      <th>Instability</th>\n",
              "      <th>Helix</th>\n",
              "      <th>Turn</th>\n",
              "      <th>Sheet</th>\n",
              "      <th>Extinction</th>\n",
              "      <th>Charge10</th>\n",
              "      <th>Charge7</th>\n",
              "      <th>Charge4</th>\n",
              "      <th>...</th>\n",
              "      <th>NonPolar</th>\n",
              "      <th>Polar</th>\n",
              "      <th>Charged</th>\n",
              "      <th>Basic</th>\n",
              "      <th>Acidic</th>\n",
              "      <th>Ala</th>\n",
              "      <th>Arg</th>\n",
              "      <th>Asn</th>\n",
              "      <th>Asp</th>\n",
              "      <th>Cys</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.019064</td>\n",
              "      <td>0.340273</td>\n",
              "      <td>0.184694</td>\n",
              "      <td>-2.247021</td>\n",
              "      <td>-2.365072</td>\n",
              "      <td>-0.641198</td>\n",
              "      <td>0.684356</td>\n",
              "      <td>0.387380</td>\n",
              "      <td>2.649837</td>\n",
              "      <td>3.546482</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.561624</td>\n",
              "      <td>3.561163</td>\n",
              "      <td>4.386968</td>\n",
              "      <td>4.699078</td>\n",
              "      <td>2.991882</td>\n",
              "      <td>-1.275096</td>\n",
              "      <td>0.502404</td>\n",
              "      <td>0.274225</td>\n",
              "      <td>2.582006</td>\n",
              "      <td>-1.256611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.354484</td>\n",
              "      <td>0.340273</td>\n",
              "      <td>0.020202</td>\n",
              "      <td>-2.247021</td>\n",
              "      <td>-2.756400</td>\n",
              "      <td>-0.641198</td>\n",
              "      <td>0.504808</td>\n",
              "      <td>0.227563</td>\n",
              "      <td>2.296024</td>\n",
              "      <td>3.107736</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.062218</td>\n",
              "      <td>4.061678</td>\n",
              "      <td>4.386968</td>\n",
              "      <td>4.699078</td>\n",
              "      <td>3.468611</td>\n",
              "      <td>-0.642608</td>\n",
              "      <td>0.502404</td>\n",
              "      <td>0.274225</td>\n",
              "      <td>2.582006</td>\n",
              "      <td>-1.256611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.287853</td>\n",
              "      <td>1.426167</td>\n",
              "      <td>-1.099181</td>\n",
              "      <td>0.267505</td>\n",
              "      <td>-0.017107</td>\n",
              "      <td>-0.641198</td>\n",
              "      <td>0.568465</td>\n",
              "      <td>1.769109</td>\n",
              "      <td>1.286124</td>\n",
              "      <td>-0.244375</td>\n",
              "      <td>...</td>\n",
              "      <td>0.192836</td>\n",
              "      <td>-0.192698</td>\n",
              "      <td>-0.146362</td>\n",
              "      <td>0.436173</td>\n",
              "      <td>-0.821949</td>\n",
              "      <td>0.622368</td>\n",
              "      <td>0.502404</td>\n",
              "      <td>-0.700179</td>\n",
              "      <td>-1.076892</td>\n",
              "      <td>-1.256611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.668644</td>\n",
              "      <td>1.426167</td>\n",
              "      <td>0.360338</td>\n",
              "      <td>0.267505</td>\n",
              "      <td>-0.408434</td>\n",
              "      <td>-0.253684</td>\n",
              "      <td>2.659384</td>\n",
              "      <td>-0.049915</td>\n",
              "      <td>-0.534483</td>\n",
              "      <td>-1.042672</td>\n",
              "      <td>...</td>\n",
              "      <td>0.693431</td>\n",
              "      <td>-0.693213</td>\n",
              "      <td>-0.862151</td>\n",
              "      <td>-0.726438</td>\n",
              "      <td>-0.821949</td>\n",
              "      <td>0.622368</td>\n",
              "      <td>0.502404</td>\n",
              "      <td>-0.700179</td>\n",
              "      <td>0.752557</td>\n",
              "      <td>1.934685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.464094</td>\n",
              "      <td>1.426167</td>\n",
              "      <td>0.116388</td>\n",
              "      <td>0.267505</td>\n",
              "      <td>-0.017107</td>\n",
              "      <td>-0.253684</td>\n",
              "      <td>2.640776</td>\n",
              "      <td>-0.916956</td>\n",
              "      <td>-1.097938</td>\n",
              "      <td>-0.989347</td>\n",
              "      <td>...</td>\n",
              "      <td>0.443134</td>\n",
              "      <td>-0.442956</td>\n",
              "      <td>-0.384958</td>\n",
              "      <td>-0.726438</td>\n",
              "      <td>0.131509</td>\n",
              "      <td>-0.010120</td>\n",
              "      <td>-0.247213</td>\n",
              "      <td>-0.700179</td>\n",
              "      <td>0.752557</td>\n",
              "      <td>0.870920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13995</th>\n",
              "      <td>1.510377</td>\n",
              "      <td>0.340273</td>\n",
              "      <td>0.697687</td>\n",
              "      <td>-0.046811</td>\n",
              "      <td>1.156876</td>\n",
              "      <td>-1.416227</td>\n",
              "      <td>0.194353</td>\n",
              "      <td>-1.336005</td>\n",
              "      <td>-1.225394</td>\n",
              "      <td>0.838501</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.307758</td>\n",
              "      <td>0.307817</td>\n",
              "      <td>0.330831</td>\n",
              "      <td>0.048636</td>\n",
              "      <td>0.608238</td>\n",
              "      <td>-1.275096</td>\n",
              "      <td>-0.247213</td>\n",
              "      <td>0.274225</td>\n",
              "      <td>0.752557</td>\n",
              "      <td>-0.192845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13996</th>\n",
              "      <td>0.360246</td>\n",
              "      <td>-0.745621</td>\n",
              "      <td>-0.994631</td>\n",
              "      <td>-0.675442</td>\n",
              "      <td>0.765549</td>\n",
              "      <td>-1.028713</td>\n",
              "      <td>0.310243</td>\n",
              "      <td>0.903326</td>\n",
              "      <td>1.151702</td>\n",
              "      <td>1.029628</td>\n",
              "      <td>...</td>\n",
              "      <td>0.192836</td>\n",
              "      <td>-0.192698</td>\n",
              "      <td>0.092235</td>\n",
              "      <td>0.436173</td>\n",
              "      <td>-0.345220</td>\n",
              "      <td>0.622368</td>\n",
              "      <td>0.502404</td>\n",
              "      <td>0.274225</td>\n",
              "      <td>0.752557</td>\n",
              "      <td>-0.192845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13997</th>\n",
              "      <td>-0.497651</td>\n",
              "      <td>1.426167</td>\n",
              "      <td>-0.825957</td>\n",
              "      <td>-0.046811</td>\n",
              "      <td>-0.799762</td>\n",
              "      <td>0.133831</td>\n",
              "      <td>1.892551</td>\n",
              "      <td>-0.129824</td>\n",
              "      <td>0.446862</td>\n",
              "      <td>0.386555</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.307758</td>\n",
              "      <td>0.307817</td>\n",
              "      <td>0.569427</td>\n",
              "      <td>0.823710</td>\n",
              "      <td>0.131509</td>\n",
              "      <td>0.622368</td>\n",
              "      <td>-0.247213</td>\n",
              "      <td>0.274225</td>\n",
              "      <td>-0.162168</td>\n",
              "      <td>0.870920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13998</th>\n",
              "      <td>-0.860474</td>\n",
              "      <td>-0.202674</td>\n",
              "      <td>0.133116</td>\n",
              "      <td>0.267505</td>\n",
              "      <td>-0.017107</td>\n",
              "      <td>-0.253684</td>\n",
              "      <td>-1.548895</td>\n",
              "      <td>0.773081</td>\n",
              "      <td>0.677398</td>\n",
              "      <td>0.023837</td>\n",
              "      <td>...</td>\n",
              "      <td>0.192836</td>\n",
              "      <td>-0.192698</td>\n",
              "      <td>0.330831</td>\n",
              "      <td>0.436173</td>\n",
              "      <td>0.131509</td>\n",
              "      <td>-0.642608</td>\n",
              "      <td>0.502404</td>\n",
              "      <td>-1.674583</td>\n",
              "      <td>-0.162168</td>\n",
              "      <td>0.870920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13999</th>\n",
              "      <td>0.672265</td>\n",
              "      <td>0.340273</td>\n",
              "      <td>-0.034164</td>\n",
              "      <td>-0.675442</td>\n",
              "      <td>1.156876</td>\n",
              "      <td>-1.803742</td>\n",
              "      <td>-0.067461</td>\n",
              "      <td>-0.316697</td>\n",
              "      <td>-0.120075</td>\n",
              "      <td>0.201764</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.558056</td>\n",
              "      <td>0.558074</td>\n",
              "      <td>-0.146362</td>\n",
              "      <td>-0.338901</td>\n",
              "      <td>-0.345220</td>\n",
              "      <td>-0.010120</td>\n",
              "      <td>-0.247213</td>\n",
              "      <td>0.274225</td>\n",
              "      <td>0.752557</td>\n",
              "      <td>-0.192845</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14000 rows × 28 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba1dca1d-d258-40ae-86aa-eadc3fc580de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba1dca1d-d258-40ae-86aa-eadc3fc580de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba1dca1d-d258-40ae-86aa-eadc3fc580de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = pd.get_dummies(df3, columns=['Class'])\n",
        "df4 = pd.get_dummies(df4, columns=['Class'])\n"
      ],
      "metadata": {
        "id": "GxLV3b3kocok"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for padding in [\"post\", \"extr\", \"mid\"]:\n",
        "  X = df3[padding].values\n",
        "  X = X.tolist()\n",
        "  X = np.stack(X)\n",
        "  y = df3.loc[:,'Class_1':'Class_7'].values\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "  X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "  y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
        "  X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
        "  y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
        "\n",
        "\n",
        "  model = noConv(1000, 64, 7)\n",
        "  model.compile(optimizer=Adam(), loss = categorical_crossentropy, metrics=[\"accuracy\"])\n",
        "  model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, verbose=1)\n",
        "  _, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "  print(\"Test accuracy:\", test_acc)\n",
        "  model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaTdZL3ViE3A",
        "outputId": "9b8679d6-5c2e-4f75-e932-8c936551574a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "175/175 [==============================] - 2s 5ms/step - loss: 1.9051 - accuracy: 0.2301\n",
            "Epoch 2/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 1.5891 - accuracy: 0.3604\n",
            "Epoch 3/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.4079 - accuracy: 0.4341\n",
            "Epoch 4/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.3063 - accuracy: 0.4714\n",
            "Epoch 5/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.1953 - accuracy: 0.5273\n",
            "Epoch 6/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.1285 - accuracy: 0.5566\n",
            "Epoch 7/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.0588 - accuracy: 0.5798\n",
            "Epoch 8/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.0181 - accuracy: 0.5954\n",
            "Epoch 9/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.9822 - accuracy: 0.6098\n",
            "Epoch 10/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.9328 - accuracy: 0.6281\n",
            "Epoch 11/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.9152 - accuracy: 0.6362\n",
            "Epoch 12/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.8890 - accuracy: 0.6464\n",
            "Epoch 13/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.8611 - accuracy: 0.6581\n",
            "Epoch 14/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.8481 - accuracy: 0.6637\n",
            "Epoch 15/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.8221 - accuracy: 0.6731\n",
            "Epoch 16/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.8209 - accuracy: 0.6697\n",
            "Epoch 17/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7913 - accuracy: 0.6804\n",
            "Epoch 18/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7785 - accuracy: 0.6883\n",
            "Epoch 19/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7587 - accuracy: 0.6935\n",
            "Epoch 20/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7599 - accuracy: 0.6955\n",
            "Epoch 21/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.7429 - accuracy: 0.6996\n",
            "Epoch 22/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7060\n",
            "Epoch 23/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.7263 - accuracy: 0.7095\n",
            "Epoch 24/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7166 - accuracy: 0.7113\n",
            "Epoch 25/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7187 - accuracy: 0.7111\n",
            "Epoch 26/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.6882 - accuracy: 0.7251\n",
            "Epoch 27/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6950 - accuracy: 0.7188\n",
            "Epoch 28/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.7243\n",
            "Epoch 29/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6953 - accuracy: 0.7214\n",
            "Epoch 30/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6756 - accuracy: 0.7262\n",
            "Epoch 31/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6693 - accuracy: 0.7289\n",
            "Epoch 32/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6745 - accuracy: 0.7286\n",
            "Epoch 33/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.7340\n",
            "Epoch 34/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6575 - accuracy: 0.7319\n",
            "Epoch 35/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6563 - accuracy: 0.7347\n",
            "Epoch 36/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.7390\n",
            "Epoch 37/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.6277 - accuracy: 0.7454\n",
            "Epoch 38/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.6275 - accuracy: 0.7471\n",
            "Epoch 39/45\n",
            "175/175 [==============================] - 1s 6ms/step - loss: 0.6224 - accuracy: 0.7504\n",
            "Epoch 40/45\n",
            "175/175 [==============================] - 1s 6ms/step - loss: 0.6239 - accuracy: 0.7473\n",
            "Epoch 41/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.6213 - accuracy: 0.7454\n",
            "Epoch 42/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6174 - accuracy: 0.7471\n",
            "Epoch 43/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.7531\n",
            "Epoch 44/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.7490\n",
            "Epoch 45/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.7561\n",
            "Test accuracy: 0.6739285588264465\n",
            "Model: \"model_46\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_47 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_138 (Dense)           (None, 64)                64064     \n",
            "                                                                 \n",
            " dropout_92 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_139 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_93 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_140 (Dense)           (None, 7)                 455       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,679\n",
            "Trainable params: 68,679\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 1.9766 - accuracy: 0.1978\n",
            "Epoch 2/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.7445 - accuracy: 0.2921\n",
            "Epoch 3/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.6277 - accuracy: 0.3588\n",
            "Epoch 4/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.5247 - accuracy: 0.4071\n",
            "Epoch 5/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.4398 - accuracy: 0.4481\n",
            "Epoch 6/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.3674 - accuracy: 0.4754\n",
            "Epoch 7/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.2930 - accuracy: 0.5068\n",
            "Epoch 8/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.2433 - accuracy: 0.5283\n",
            "Epoch 9/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 1.1956 - accuracy: 0.5504\n",
            "Epoch 10/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 1.1440 - accuracy: 0.5709\n",
            "Epoch 11/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.0981 - accuracy: 0.5878\n",
            "Epoch 12/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.0653 - accuracy: 0.6053\n",
            "Epoch 13/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.0406 - accuracy: 0.6146\n",
            "Epoch 14/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.0109 - accuracy: 0.6218\n",
            "Epoch 15/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.9888 - accuracy: 0.6366\n",
            "Epoch 16/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.9541 - accuracy: 0.6520\n",
            "Epoch 17/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.9113 - accuracy: 0.6680\n",
            "Epoch 18/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.9126 - accuracy: 0.6646\n",
            "Epoch 19/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.8853 - accuracy: 0.6815\n",
            "Epoch 20/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.8636 - accuracy: 0.6862\n",
            "Epoch 21/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.8427 - accuracy: 0.6938\n",
            "Epoch 22/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.8428 - accuracy: 0.6914\n",
            "Epoch 23/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.8359 - accuracy: 0.6979\n",
            "Epoch 24/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.8190 - accuracy: 0.7037\n",
            "Epoch 25/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7972 - accuracy: 0.7118\n",
            "Epoch 26/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7848 - accuracy: 0.7167\n",
            "Epoch 27/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7749 - accuracy: 0.7238\n",
            "Epoch 28/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.7716 - accuracy: 0.7245\n",
            "Epoch 29/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.7496 - accuracy: 0.7312\n",
            "Epoch 30/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.7397 - accuracy: 0.7329\n",
            "Epoch 31/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.7349 - accuracy: 0.7362\n",
            "Epoch 32/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.7255 - accuracy: 0.7412\n",
            "Epoch 33/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.7171 - accuracy: 0.7431\n",
            "Epoch 34/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.7162 - accuracy: 0.7466\n",
            "Epoch 35/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.7072 - accuracy: 0.7455\n",
            "Epoch 36/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6862 - accuracy: 0.7573\n",
            "Epoch 37/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6853 - accuracy: 0.7527\n",
            "Epoch 38/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.7619\n",
            "Epoch 39/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6750 - accuracy: 0.7582\n",
            "Epoch 40/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.7624\n",
            "Epoch 41/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6819 - accuracy: 0.7559\n",
            "Epoch 42/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.7590\n",
            "Epoch 43/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.7703\n",
            "Epoch 44/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6564 - accuracy: 0.7692\n",
            "Epoch 45/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6340 - accuracy: 0.7735\n",
            "Test accuracy: 0.6228571534156799\n",
            "Model: \"model_47\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_48 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_141 (Dense)           (None, 64)                64064     \n",
            "                                                                 \n",
            " dropout_94 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_142 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_95 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_143 (Dense)           (None, 7)                 455       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,679\n",
            "Trainable params: 68,679\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 1.7568 - accuracy: 0.3237\n",
            "Epoch 2/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.2695 - accuracy: 0.5105\n",
            "Epoch 3/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.0741 - accuracy: 0.5879\n",
            "Epoch 4/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.9384 - accuracy: 0.6525\n",
            "Epoch 5/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.8171 - accuracy: 0.6933\n",
            "Epoch 6/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.7280\n",
            "Epoch 7/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.7497\n",
            "Epoch 8/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6285 - accuracy: 0.7667\n",
            "Epoch 9/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.7806\n",
            "Epoch 10/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.7921\n",
            "Epoch 11/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.5325 - accuracy: 0.8014\n",
            "Epoch 12/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.8062\n",
            "Epoch 13/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.8159\n",
            "Epoch 14/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.8251\n",
            "Epoch 15/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.8263\n",
            "Epoch 16/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.4477 - accuracy: 0.8311\n",
            "Epoch 17/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.4305 - accuracy: 0.8333\n",
            "Epoch 18/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8375\n",
            "Epoch 19/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8433\n",
            "Epoch 20/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3943 - accuracy: 0.8504\n",
            "Epoch 21/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3914 - accuracy: 0.8501\n",
            "Epoch 22/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3873 - accuracy: 0.8520\n",
            "Epoch 23/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8559\n",
            "Epoch 24/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8604\n",
            "Epoch 25/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8578\n",
            "Epoch 26/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3610 - accuracy: 0.8605\n",
            "Epoch 27/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8612\n",
            "Epoch 28/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3447 - accuracy: 0.8658\n",
            "Epoch 29/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3393 - accuracy: 0.8689\n",
            "Epoch 30/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3454 - accuracy: 0.8664\n",
            "Epoch 31/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8679\n",
            "Epoch 32/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.8707\n",
            "Epoch 33/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3122 - accuracy: 0.8814\n",
            "Epoch 34/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3307 - accuracy: 0.8738\n",
            "Epoch 35/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3240 - accuracy: 0.8769\n",
            "Epoch 36/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3197 - accuracy: 0.8788\n",
            "Epoch 37/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3129 - accuracy: 0.8776\n",
            "Epoch 38/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3069 - accuracy: 0.8828\n",
            "Epoch 39/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3225 - accuracy: 0.8746\n",
            "Epoch 40/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3103 - accuracy: 0.8846\n",
            "Epoch 41/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3051 - accuracy: 0.8820\n",
            "Epoch 42/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3088 - accuracy: 0.8847\n",
            "Epoch 43/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.2973 - accuracy: 0.8853\n",
            "Epoch 44/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3001 - accuracy: 0.8840\n",
            "Epoch 45/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3037 - accuracy: 0.8842\n",
            "Test accuracy: 0.8025000095367432\n",
            "Model: \"model_48\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_49 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_144 (Dense)           (None, 64)                64064     \n",
            "                                                                 \n",
            " dropout_96 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_145 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_97 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_146 (Dense)           (None, 7)                 455       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,679\n",
            "Trainable params: 68,679\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The paddings got the following accuracy:\n",
        "\n",
        "1.   post - 67.4%\n",
        "2.   extreme - 62.3%\n",
        "3.   mid - 80.2%"
      ],
      "metadata": {
        "id": "DwsV0aU6sQOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Middle padding clearly got the best accuracy within the given dataset and tested model."
      ],
      "metadata": {
        "id": "b2TV1-sjsSPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next part i will use three architectures:\n",
        "\n",
        "\n",
        "*   no convolution (Architecture #1 already tested here)\n",
        "*   one convolutional layer (Architecture #2)\n",
        "*   five convolutional layers (Architecture #3)\n",
        "\n",
        "\n",
        "I will also use the physico-chemical tabular data comprised in scaled_df to the same tasks with the same architectures.\n",
        "\n",
        "The analysis will also be done for three separate datasets: \\\n",
        "\n",
        "Dataset 1: 14000 enzymes of 7 classes, 14000 non-enzymes. (this notebook)\\\n",
        "Dataset 2: 5000 enzymes from 5 specific subclasses and 5000 non-enzymes. (notebook 2) \\\n",
        "Dataset 3: task 2: 770 proteins from cytoplasm, membrane and extracellular space classified to 3 classes based on their location.\n",
        "\n"
      ],
      "metadata": {
        "id": "GQyVtN39sdLb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Data"
      ],
      "metadata": {
        "id": "oSfrud_mVLZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(X,y):\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "  X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "  y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
        "  X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
        "  y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "dsECC7c5WDAw"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# task1_sequence\n",
        "X = df[\"mid\"].values\n",
        "X = X.tolist()\n",
        "X = np.stack(X)\n",
        "y = df['Binary'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = split_data(X,y)\n",
        "\n",
        "#task1_tabular\n",
        "X2 = scaled_df.values\n",
        "y2 = df2['Binary'].values\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = split_data(X2,y2)\n",
        "\n",
        "#task2_sequence\n",
        "X3 = df3[\"mid\"].values\n",
        "X3 = X3.tolist()\n",
        "X3 = np.stack(X3)\n",
        "y3 = df3.loc[:,'Class_1':'Class_7'].values\n",
        "\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = split_data(X3,y3)\n",
        "\n",
        "\n",
        "#task2_tabular\n",
        "X4 = scaled_df2.values\n",
        "y4 = df4.loc[:,'Class_1':'Class_7'].values\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = split_data(X4,y4)\n",
        "\n"
      ],
      "metadata": {
        "id": "HO564slDVcDe"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tabular = 28\n",
        "input_sequence = 1000\n",
        "hidden_size = 64"
      ],
      "metadata": {
        "id": "GTobg9GmYZis"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_model(architecture, tabular, out_classes, X_train, X_test, y_train, y_test):\n",
        "\n",
        "    if architecture == \"no_conv\":\n",
        "      if tabular == True:\n",
        "        model = noConv(input_tabular, hidden_size, out_classes)\n",
        "      elif tabular == False:\n",
        "        model = noConv(input_sequence, hidden_size, out_classes)\n",
        "\n",
        "    if architecture == \"one_conv\":\n",
        "      if tabular == True:\n",
        "        model = oneCNN(input_tabular, out_classes)\n",
        "      elif tabular == False:\n",
        "        model = oneCNN(input_sequence, out_classes)\n",
        "\n",
        "    if architecture == \"five_conv\":\n",
        "      if tabular == True:\n",
        "        model = stackedCNN(input_tabular, out_classes)\n",
        "      elif tabular == False:\n",
        "        model = stackedCNN(input_sequence, out_classes)\n",
        "\n",
        "    if out_classes == 1:\n",
        "      loss = binary_crossentropy\n",
        "    else:  \n",
        "      loss = categorical_crossentropy\n",
        "\n",
        "    model.compile(optimizer=Adam(), loss = loss, metrics=[\"accuracy\"])\n",
        "    model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, verbose=1)\n",
        "    _, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(str(out_classes) + \" \" + str(tabular) + \" \" + architecture)\n",
        "    print(\"Test accuracy:\", test_acc)\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "NKKbieLfW81D"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rewriting this as a loop takes the same amount of space and is less readable:"
      ],
      "metadata": {
        "id": "b_maRUtQqQ_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = run_model(\"no_conv\", False, 1, X_train, X_test, y_train, y_test)\n",
        "model = run_model(\"no_conv\", True,  1, X_train2, X_test2, y_train2, y_test2)\n",
        "model = run_model(\"no_conv\", False, 7, X_train3, X_test3, y_train3, y_test3)\n",
        "model = run_model(\"no_conv\", True,  7, X_train4, X_test4, y_train4, y_test4)\n",
        "\n",
        "model = run_model(\"one_conv\", False, 1, X_train, X_test, y_train, y_test)\n",
        "model = run_model(\"one_conv\", True,  1, X_train2, X_test2, y_train2, y_test2)\n",
        "model = run_model(\"one_conv\", False, 7, X_train3, X_test3, y_train3, y_test3)\n",
        "model = run_model(\"one_conv\", True,  7, X_train4, X_test4, y_train4, y_test4)\n",
        "\n",
        "model = run_model(\"five_conv\", False, 1, X_train, X_test, y_train, y_test)      #model1\n",
        "model = run_model(\"five_conv\", True,  1, X_train2, X_test2, y_train2, y_test2)  #model2\n",
        "model = run_model(\"five_conv\", False, 7, X_train3, X_test3, y_train3, y_test3)  #model3  \n",
        "model = run_model(\"five_conv\", True,  7, X_train4, X_test4, y_train4, y_test4)  #model4\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVxj2HhtZStj",
        "outputId": "77e378b9-c19f-4b2e-cc2d-5c71ec494fe4"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.6622 - accuracy: 0.6065\n",
            "Epoch 2/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5665 - accuracy: 0.6813\n",
            "Epoch 3/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5322 - accuracy: 0.7092\n",
            "Epoch 4/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5053 - accuracy: 0.7283\n",
            "Epoch 5/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4807 - accuracy: 0.7440\n",
            "Epoch 6/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4647 - accuracy: 0.7543\n",
            "Epoch 7/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4533 - accuracy: 0.7622\n",
            "Epoch 8/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4392 - accuracy: 0.7690\n",
            "Epoch 9/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4331 - accuracy: 0.7729\n",
            "Epoch 10/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4215 - accuracy: 0.7794\n",
            "Epoch 11/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4157 - accuracy: 0.7830\n",
            "Epoch 12/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4082 - accuracy: 0.7872\n",
            "Epoch 13/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4005 - accuracy: 0.7915\n",
            "Epoch 14/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3978 - accuracy: 0.7928\n",
            "Epoch 15/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3896 - accuracy: 0.7941\n",
            "Epoch 16/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3856 - accuracy: 0.7992\n",
            "Epoch 17/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3803 - accuracy: 0.8005\n",
            "Epoch 18/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3798 - accuracy: 0.7982\n",
            "Epoch 19/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3733 - accuracy: 0.8053\n",
            "Epoch 20/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3741 - accuracy: 0.8022\n",
            "Epoch 21/45\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3671 - accuracy: 0.8049\n",
            "Epoch 22/45\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3633 - accuracy: 0.8062\n",
            "Epoch 23/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3608 - accuracy: 0.8099\n",
            "Epoch 24/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3566 - accuracy: 0.8121\n",
            "Epoch 25/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3538 - accuracy: 0.8123\n",
            "Epoch 26/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3565 - accuracy: 0.8101\n",
            "Epoch 27/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3539 - accuracy: 0.8116\n",
            "Epoch 28/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3483 - accuracy: 0.8142\n",
            "Epoch 29/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3486 - accuracy: 0.8138\n",
            "Epoch 30/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3473 - accuracy: 0.8161\n",
            "Epoch 31/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3422 - accuracy: 0.8171\n",
            "Epoch 32/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3376 - accuracy: 0.8198\n",
            "Epoch 33/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3365 - accuracy: 0.8199\n",
            "Epoch 34/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.8209\n",
            "Epoch 35/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3328 - accuracy: 0.8191\n",
            "Epoch 36/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3335 - accuracy: 0.8192\n",
            "Epoch 37/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3307 - accuracy: 0.8225\n",
            "Epoch 38/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3307 - accuracy: 0.8224\n",
            "Epoch 39/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3266 - accuracy: 0.8234\n",
            "Epoch 40/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3295 - accuracy: 0.8234\n",
            "Epoch 41/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3251 - accuracy: 0.8228\n",
            "Epoch 42/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8250\n",
            "Epoch 43/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3247 - accuracy: 0.8248\n",
            "Epoch 44/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3186 - accuracy: 0.8276\n",
            "Epoch 45/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3194 - accuracy: 0.8288\n",
            "1 False no_conv\n",
            "Test accuracy: 0.7007142901420593\n",
            "Model: \"model_45\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_50 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_135 (Dense)           (None, 64)                64064     \n",
            "                                                                 \n",
            " dropout_84 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_136 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_85 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_137 (Dense)           (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,289\n",
            "Trainable params: 68,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5935 - accuracy: 0.6774\n",
            "Epoch 2/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5434 - accuracy: 0.7179\n",
            "Epoch 3/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5231 - accuracy: 0.7337\n",
            "Epoch 4/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5074 - accuracy: 0.7436\n",
            "Epoch 5/45\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.4986 - accuracy: 0.7503\n",
            "Epoch 6/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4910 - accuracy: 0.7521\n",
            "Epoch 7/45\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.4842 - accuracy: 0.7563\n",
            "Epoch 8/45\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.4743 - accuracy: 0.7645\n",
            "Epoch 9/45\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.4714 - accuracy: 0.7654\n",
            "Epoch 10/45\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.4708 - accuracy: 0.7655\n",
            "Epoch 11/45\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.4639 - accuracy: 0.7689\n",
            "Epoch 12/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4599 - accuracy: 0.7730\n",
            "Epoch 13/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4576 - accuracy: 0.7723\n",
            "Epoch 14/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4565 - accuracy: 0.7761\n",
            "Epoch 15/45\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.4536 - accuracy: 0.7759\n",
            "Epoch 16/45\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.4539 - accuracy: 0.7751\n",
            "Epoch 17/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4523 - accuracy: 0.7745\n",
            "Epoch 18/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4506 - accuracy: 0.7771\n",
            "Epoch 19/45\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.4509 - accuracy: 0.7763\n",
            "Epoch 20/45\n",
            "350/350 [==============================] - 1s 2ms/step - loss: 0.4503 - accuracy: 0.7787\n",
            "Epoch 21/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4466 - accuracy: 0.7785\n",
            "Epoch 22/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4437 - accuracy: 0.7804\n",
            "Epoch 23/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4458 - accuracy: 0.7803\n",
            "Epoch 24/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4438 - accuracy: 0.7810\n",
            "Epoch 25/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4408 - accuracy: 0.7823\n",
            "Epoch 26/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4401 - accuracy: 0.7821\n",
            "Epoch 27/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4389 - accuracy: 0.7810\n",
            "Epoch 28/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4406 - accuracy: 0.7781\n",
            "Epoch 29/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4398 - accuracy: 0.7845\n",
            "Epoch 30/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4373 - accuracy: 0.7834\n",
            "Epoch 31/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4379 - accuracy: 0.7826\n",
            "Epoch 32/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4396 - accuracy: 0.7835\n",
            "Epoch 33/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4368 - accuracy: 0.7824\n",
            "Epoch 34/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4359 - accuracy: 0.7840\n",
            "Epoch 35/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4351 - accuracy: 0.7863\n",
            "Epoch 36/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4340 - accuracy: 0.7839\n",
            "Epoch 37/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4326 - accuracy: 0.7858\n",
            "Epoch 38/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4353 - accuracy: 0.7848\n",
            "Epoch 39/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4350 - accuracy: 0.7862\n",
            "Epoch 40/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4317 - accuracy: 0.7854\n",
            "Epoch 41/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4303 - accuracy: 0.7850\n",
            "Epoch 42/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4325 - accuracy: 0.7867\n",
            "Epoch 43/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4322 - accuracy: 0.7869\n",
            "Epoch 44/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4337 - accuracy: 0.7836\n",
            "Epoch 45/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4291 - accuracy: 0.7881\n",
            "1 True no_conv\n",
            "Test accuracy: 0.7944642901420593\n",
            "Model: \"model_46\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_51 (InputLayer)       [(None, 28)]              0         \n",
            "                                                                 \n",
            " dense_138 (Dense)           (None, 64)                1856      \n",
            "                                                                 \n",
            " dropout_86 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_139 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_87 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_140 (Dense)           (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,081\n",
            "Trainable params: 6,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 1.7567 - accuracy: 0.3295\n",
            "Epoch 2/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 1.2942 - accuracy: 0.4993\n",
            "Epoch 3/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.0794 - accuracy: 0.5938\n",
            "Epoch 4/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.9346 - accuracy: 0.6475\n",
            "Epoch 5/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.8289 - accuracy: 0.6928\n",
            "Epoch 6/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7589 - accuracy: 0.7151\n",
            "Epoch 7/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6978 - accuracy: 0.7366\n",
            "Epoch 8/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6538 - accuracy: 0.7566\n",
            "Epoch 9/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6097 - accuracy: 0.7737\n",
            "Epoch 10/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.7814\n",
            "Epoch 11/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.5618 - accuracy: 0.7891\n",
            "Epoch 12/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.5309 - accuracy: 0.8019\n",
            "Epoch 13/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.8017\n",
            "Epoch 14/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.5095 - accuracy: 0.8082\n",
            "Epoch 15/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.8100\n",
            "Epoch 16/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.4709 - accuracy: 0.8220\n",
            "Epoch 17/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.8214\n",
            "Epoch 18/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.4560 - accuracy: 0.8257\n",
            "Epoch 19/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.8313\n",
            "Epoch 20/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.4416 - accuracy: 0.8367\n",
            "Epoch 21/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8432\n",
            "Epoch 22/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.4148 - accuracy: 0.8451\n",
            "Epoch 23/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8478\n",
            "Epoch 24/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.4103 - accuracy: 0.8469\n",
            "Epoch 25/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3920 - accuracy: 0.8507\n",
            "Epoch 26/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3890 - accuracy: 0.8546\n",
            "Epoch 27/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8552\n",
            "Epoch 28/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3720 - accuracy: 0.8588\n",
            "Epoch 29/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8581\n",
            "Epoch 30/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3714 - accuracy: 0.8590\n",
            "Epoch 31/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3772 - accuracy: 0.8603\n",
            "Epoch 32/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3600 - accuracy: 0.8638\n",
            "Epoch 33/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3624 - accuracy: 0.8654\n",
            "Epoch 34/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3508 - accuracy: 0.8663\n",
            "Epoch 35/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3600 - accuracy: 0.8689\n",
            "Epoch 36/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3388 - accuracy: 0.8692\n",
            "Epoch 37/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8702\n",
            "Epoch 38/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3455 - accuracy: 0.8726\n",
            "Epoch 39/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3552 - accuracy: 0.8652\n",
            "Epoch 40/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8764\n",
            "Epoch 41/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3314 - accuracy: 0.8779\n",
            "Epoch 42/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3249 - accuracy: 0.8760\n",
            "Epoch 43/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3167 - accuracy: 0.8814\n",
            "Epoch 44/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.8780\n",
            "Epoch 45/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3119 - accuracy: 0.8828\n",
            "7 False no_conv\n",
            "Test accuracy: 0.8046428561210632\n",
            "Model: \"model_47\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_52 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_141 (Dense)           (None, 64)                64064     \n",
            "                                                                 \n",
            " dropout_88 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_142 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_89 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_143 (Dense)           (None, 7)                 455       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,679\n",
            "Trainable params: 68,679\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 1.6313 - accuracy: 0.3720\n",
            "Epoch 2/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.2721 - accuracy: 0.5288\n",
            "Epoch 3/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.1669 - accuracy: 0.5711\n",
            "Epoch 4/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.0925 - accuracy: 0.6024\n",
            "Epoch 5/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 1.0307 - accuracy: 0.6331\n",
            "Epoch 6/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.9933 - accuracy: 0.6524\n",
            "Epoch 7/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.9588 - accuracy: 0.6639\n",
            "Epoch 8/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.9309 - accuracy: 0.6807\n",
            "Epoch 9/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.9054 - accuracy: 0.6843\n",
            "Epoch 10/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.8929 - accuracy: 0.6910\n",
            "Epoch 11/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.8694 - accuracy: 0.6957\n",
            "Epoch 12/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.8624 - accuracy: 0.7057\n",
            "Epoch 13/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.8460 - accuracy: 0.7089\n",
            "Epoch 14/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.8224 - accuracy: 0.7196\n",
            "Epoch 15/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.8237 - accuracy: 0.7163\n",
            "Epoch 16/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.8138 - accuracy: 0.7215\n",
            "Epoch 17/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7903 - accuracy: 0.7248\n",
            "Epoch 18/45\n",
            "175/175 [==============================] - 0s 2ms/step - loss: 0.7876 - accuracy: 0.7270\n",
            "Epoch 19/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7753 - accuracy: 0.7309\n",
            "Epoch 20/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7734 - accuracy: 0.7346\n",
            "Epoch 21/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7693 - accuracy: 0.7366\n",
            "Epoch 22/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7532 - accuracy: 0.7422\n",
            "Epoch 23/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7557 - accuracy: 0.7399\n",
            "Epoch 24/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7448\n",
            "Epoch 25/45\n",
            "175/175 [==============================] - 0s 2ms/step - loss: 0.7402 - accuracy: 0.7482\n",
            "Epoch 26/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.7409\n",
            "Epoch 27/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7270 - accuracy: 0.7487\n",
            "Epoch 28/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7262 - accuracy: 0.7523\n",
            "Epoch 29/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7271 - accuracy: 0.7522\n",
            "Epoch 30/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7110 - accuracy: 0.7521\n",
            "Epoch 31/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7094 - accuracy: 0.7582\n",
            "Epoch 32/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7129 - accuracy: 0.7532\n",
            "Epoch 33/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7040 - accuracy: 0.7609\n",
            "Epoch 34/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.7048 - accuracy: 0.7558\n",
            "Epoch 35/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.7630\n",
            "Epoch 36/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.7629\n",
            "Epoch 37/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.7700\n",
            "Epoch 38/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.7623\n",
            "Epoch 39/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.7680\n",
            "Epoch 40/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6952 - accuracy: 0.7676\n",
            "Epoch 41/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6753 - accuracy: 0.7681\n",
            "Epoch 42/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6708 - accuracy: 0.7699\n",
            "Epoch 43/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6670 - accuracy: 0.7704\n",
            "Epoch 44/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.7671\n",
            "Epoch 45/45\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.6648 - accuracy: 0.7720\n",
            "7 True no_conv\n",
            "Test accuracy: 0.852142870426178\n",
            "Model: \"model_48\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_53 (InputLayer)       [(None, 28)]              0         \n",
            "                                                                 \n",
            " dense_144 (Dense)           (None, 64)                1856      \n",
            "                                                                 \n",
            " dropout_90 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_145 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_91 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_146 (Dense)           (None, 7)                 455       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,471\n",
            "Trainable params: 6,471\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/45\n",
            "350/350 [==============================] - 2s 3ms/step - loss: 0.5581 - accuracy: 0.6854\n",
            "Epoch 2/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4756 - accuracy: 0.7454\n",
            "Epoch 3/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4424 - accuracy: 0.7644\n",
            "Epoch 4/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4142 - accuracy: 0.7825\n",
            "Epoch 5/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3918 - accuracy: 0.7909\n",
            "Epoch 6/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3719 - accuracy: 0.8016\n",
            "Epoch 7/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3584 - accuracy: 0.8108\n",
            "Epoch 8/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3462 - accuracy: 0.8144\n",
            "Epoch 9/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.8206\n",
            "Epoch 10/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3241 - accuracy: 0.8250\n",
            "Epoch 11/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3143 - accuracy: 0.8295\n",
            "Epoch 12/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3097 - accuracy: 0.8309\n",
            "Epoch 13/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3065 - accuracy: 0.8333\n",
            "Epoch 14/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2987 - accuracy: 0.8387\n",
            "Epoch 15/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2930 - accuracy: 0.8363\n",
            "Epoch 16/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2920 - accuracy: 0.8373\n",
            "Epoch 17/45\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2825 - accuracy: 0.8454\n",
            "Epoch 18/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2751 - accuracy: 0.8485\n",
            "Epoch 19/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2750 - accuracy: 0.8502\n",
            "Epoch 20/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2730 - accuracy: 0.8497\n",
            "Epoch 21/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2714 - accuracy: 0.8495\n",
            "Epoch 22/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2671 - accuracy: 0.8507\n",
            "Epoch 23/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2653 - accuracy: 0.8517\n",
            "Epoch 24/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2631 - accuracy: 0.8517\n",
            "Epoch 25/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2594 - accuracy: 0.8544\n",
            "Epoch 26/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2586 - accuracy: 0.8555\n",
            "Epoch 27/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2572 - accuracy: 0.8541\n",
            "Epoch 28/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2527 - accuracy: 0.8542\n",
            "Epoch 29/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2548 - accuracy: 0.8544\n",
            "Epoch 30/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2487 - accuracy: 0.8579\n",
            "Epoch 31/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2486 - accuracy: 0.8561\n",
            "Epoch 32/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2516 - accuracy: 0.8577\n",
            "Epoch 33/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2458 - accuracy: 0.8599\n",
            "Epoch 34/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2441 - accuracy: 0.8589\n",
            "Epoch 35/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2450 - accuracy: 0.8601\n",
            "Epoch 36/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2425 - accuracy: 0.8598\n",
            "Epoch 37/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2405 - accuracy: 0.8617\n",
            "Epoch 38/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2404 - accuracy: 0.8618\n",
            "Epoch 39/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2409 - accuracy: 0.8624\n",
            "Epoch 40/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2381 - accuracy: 0.8628\n",
            "Epoch 41/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2362 - accuracy: 0.8630\n",
            "Epoch 42/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2362 - accuracy: 0.8631\n",
            "Epoch 43/45\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2355 - accuracy: 0.8637\n",
            "Epoch 44/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2316 - accuracy: 0.8682\n",
            "Epoch 45/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.2321 - accuracy: 0.8645\n",
            "1 False one_conv\n",
            "Test accuracy: 0.6953571438789368\n",
            "Model: \"model_49\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_54 (InputLayer)       [(None, 1000, 1)]         0         \n",
            "                                                                 \n",
            " conv1d_88 (Conv1D)          (None, 998, 32)           128       \n",
            "                                                                 \n",
            " flatten_24 (Flatten)        (None, 31936)             0         \n",
            "                                                                 \n",
            " dense_147 (Dense)           (None, 16)                510992    \n",
            "                                                                 \n",
            " dense_148 (Dense)           (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_149 (Dense)           (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 511,265\n",
            "Trainable params: 511,265\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.5163 - accuracy: 0.7357\n",
            "Epoch 2/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4623 - accuracy: 0.7679\n",
            "Epoch 3/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4414 - accuracy: 0.7806\n",
            "Epoch 4/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4296 - accuracy: 0.7850\n",
            "Epoch 5/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4221 - accuracy: 0.7896\n",
            "Epoch 6/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4151 - accuracy: 0.7920\n",
            "Epoch 7/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4084 - accuracy: 0.7967\n",
            "Epoch 8/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4043 - accuracy: 0.7996\n",
            "Epoch 9/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.4008 - accuracy: 0.8002\n",
            "Epoch 10/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3953 - accuracy: 0.8033\n",
            "Epoch 11/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3933 - accuracy: 0.8016\n",
            "Epoch 12/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3917 - accuracy: 0.8033\n",
            "Epoch 13/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3893 - accuracy: 0.8059\n",
            "Epoch 14/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3865 - accuracy: 0.8083\n",
            "Epoch 15/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3854 - accuracy: 0.8045\n",
            "Epoch 16/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3824 - accuracy: 0.8067\n",
            "Epoch 17/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3796 - accuracy: 0.8087\n",
            "Epoch 18/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3773 - accuracy: 0.8104\n",
            "Epoch 19/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3769 - accuracy: 0.8108\n",
            "Epoch 20/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3763 - accuracy: 0.8092\n",
            "Epoch 21/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3750 - accuracy: 0.8107\n",
            "Epoch 22/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3739 - accuracy: 0.8101\n",
            "Epoch 23/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3725 - accuracy: 0.8126\n",
            "Epoch 24/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3711 - accuracy: 0.8120\n",
            "Epoch 25/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3691 - accuracy: 0.8131\n",
            "Epoch 26/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3681 - accuracy: 0.8125\n",
            "Epoch 27/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3678 - accuracy: 0.8135\n",
            "Epoch 28/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3650 - accuracy: 0.8171\n",
            "Epoch 29/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3642 - accuracy: 0.8165\n",
            "Epoch 30/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3633 - accuracy: 0.8172\n",
            "Epoch 31/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3627 - accuracy: 0.8177\n",
            "Epoch 32/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3620 - accuracy: 0.8163\n",
            "Epoch 33/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3610 - accuracy: 0.8170\n",
            "Epoch 34/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3607 - accuracy: 0.8169\n",
            "Epoch 35/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3593 - accuracy: 0.8150\n",
            "Epoch 36/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3585 - accuracy: 0.8164\n",
            "Epoch 37/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3565 - accuracy: 0.8205\n",
            "Epoch 38/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3576 - accuracy: 0.8185\n",
            "Epoch 39/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3555 - accuracy: 0.8175\n",
            "Epoch 40/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3569 - accuracy: 0.8173\n",
            "Epoch 41/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3544 - accuracy: 0.8195\n",
            "Epoch 42/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3538 - accuracy: 0.8199\n",
            "Epoch 43/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3520 - accuracy: 0.8218\n",
            "Epoch 44/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3535 - accuracy: 0.8175\n",
            "Epoch 45/45\n",
            "350/350 [==============================] - 1s 3ms/step - loss: 0.3498 - accuracy: 0.8203\n",
            "1 True one_conv\n",
            "Test accuracy: 0.787678599357605\n",
            "Model: \"model_50\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_55 (InputLayer)       [(None, 28, 1)]           0         \n",
            "                                                                 \n",
            " conv1d_89 (Conv1D)          (None, 26, 32)            128       \n",
            "                                                                 \n",
            " flatten_25 (Flatten)        (None, 832)               0         \n",
            "                                                                 \n",
            " dense_150 (Dense)           (None, 16)                13328     \n",
            "                                                                 \n",
            " dense_151 (Dense)           (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_152 (Dense)           (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,601\n",
            "Trainable params: 13,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 1.4974 - accuracy: 0.4136\n",
            "Epoch 2/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.9719 - accuracy: 0.6263\n",
            "Epoch 3/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.7498 - accuracy: 0.7069\n",
            "Epoch 4/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.6218 - accuracy: 0.7544\n",
            "Epoch 5/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5223 - accuracy: 0.8049\n",
            "Epoch 6/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.4425 - accuracy: 0.8367\n",
            "Epoch 7/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.3796 - accuracy: 0.8623\n",
            "Epoch 8/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.3202 - accuracy: 0.8846\n",
            "Epoch 9/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.2747 - accuracy: 0.8993\n",
            "Epoch 10/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.2502 - accuracy: 0.9086\n",
            "Epoch 11/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.2257 - accuracy: 0.9173\n",
            "Epoch 12/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.2164 - accuracy: 0.9237\n",
            "Epoch 13/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.1858 - accuracy: 0.9335\n",
            "Epoch 14/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.1626 - accuracy: 0.9406\n",
            "Epoch 15/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.1490 - accuracy: 0.9479\n",
            "Epoch 16/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.1481 - accuracy: 0.9487\n",
            "Epoch 17/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.1582 - accuracy: 0.9460\n",
            "Epoch 18/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.1463 - accuracy: 0.9478\n",
            "Epoch 19/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.1471 - accuracy: 0.9463\n",
            "Epoch 20/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.1283 - accuracy: 0.9553\n",
            "Epoch 21/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.1329 - accuracy: 0.9538\n",
            "Epoch 22/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.1251 - accuracy: 0.9548\n",
            "Epoch 23/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.1156 - accuracy: 0.9580\n",
            "Epoch 24/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.1042 - accuracy: 0.9611\n",
            "Epoch 25/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.1068 - accuracy: 0.9612\n",
            "Epoch 26/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.1000 - accuracy: 0.9634\n",
            "Epoch 27/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.1013 - accuracy: 0.9643\n",
            "Epoch 28/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.1036 - accuracy: 0.9636\n",
            "Epoch 29/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.1013 - accuracy: 0.9638\n",
            "Epoch 30/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.0983 - accuracy: 0.9639\n",
            "Epoch 31/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.0928 - accuracy: 0.9655\n",
            "Epoch 32/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.0924 - accuracy: 0.9677\n",
            "Epoch 33/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.0873 - accuracy: 0.9689\n",
            "Epoch 34/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.0877 - accuracy: 0.9682\n",
            "Epoch 35/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.0898 - accuracy: 0.9673\n",
            "Epoch 36/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.0860 - accuracy: 0.9698\n",
            "Epoch 37/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.0908 - accuracy: 0.9684\n",
            "Epoch 38/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.1071 - accuracy: 0.9627\n",
            "Epoch 39/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.1014 - accuracy: 0.9648\n",
            "Epoch 40/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.0850 - accuracy: 0.9679\n",
            "Epoch 41/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.0767 - accuracy: 0.9721\n",
            "Epoch 42/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.0678 - accuracy: 0.9756\n",
            "Epoch 43/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.0653 - accuracy: 0.9765\n",
            "Epoch 44/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.0663 - accuracy: 0.9754\n",
            "Epoch 45/45\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.0661 - accuracy: 0.9753\n",
            "7 False one_conv\n",
            "Test accuracy: 0.7892857193946838\n",
            "Model: \"model_51\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_56 (InputLayer)       [(None, 1000, 1)]         0         \n",
            "                                                                 \n",
            " conv1d_90 (Conv1D)          (None, 998, 32)           128       \n",
            "                                                                 \n",
            " flatten_26 (Flatten)        (None, 31936)             0         \n",
            "                                                                 \n",
            " dense_153 (Dense)           (None, 16)                510992    \n",
            "                                                                 \n",
            " dense_154 (Dense)           (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_155 (Dense)           (None, 7)                 63        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 511,319\n",
            "Trainable params: 511,319\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 1.4126 - accuracy: 0.5109\n",
            "Epoch 2/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.9104 - accuracy: 0.6899\n",
            "Epoch 3/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.7970 - accuracy: 0.7321\n",
            "Epoch 4/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.7341 - accuracy: 0.7580\n",
            "Epoch 5/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6776 - accuracy: 0.7834\n",
            "Epoch 6/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6409 - accuracy: 0.7970\n",
            "Epoch 7/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6170 - accuracy: 0.8022\n",
            "Epoch 8/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.5817 - accuracy: 0.8154\n",
            "Epoch 9/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.5558 - accuracy: 0.8260\n",
            "Epoch 10/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.5334 - accuracy: 0.8313\n",
            "Epoch 11/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.5216 - accuracy: 0.8379\n",
            "Epoch 12/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.5028 - accuracy: 0.8428\n",
            "Epoch 13/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.4877 - accuracy: 0.8495\n",
            "Epoch 14/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.4740 - accuracy: 0.8529\n",
            "Epoch 15/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.4630 - accuracy: 0.8545\n",
            "Epoch 16/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.4530 - accuracy: 0.8613\n",
            "Epoch 17/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.4427 - accuracy: 0.8629\n",
            "Epoch 18/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.4339 - accuracy: 0.8666\n",
            "Epoch 19/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.4216 - accuracy: 0.8670\n",
            "Epoch 20/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.4146 - accuracy: 0.8701\n",
            "Epoch 21/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.4053 - accuracy: 0.8741\n",
            "Epoch 22/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3947 - accuracy: 0.8773\n",
            "Epoch 23/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3907 - accuracy: 0.8779\n",
            "Epoch 24/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3850 - accuracy: 0.8800\n",
            "Epoch 25/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3798 - accuracy: 0.8840\n",
            "Epoch 26/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3724 - accuracy: 0.8848\n",
            "Epoch 27/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3652 - accuracy: 0.8876\n",
            "Epoch 28/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3577 - accuracy: 0.8877\n",
            "Epoch 29/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3587 - accuracy: 0.8884\n",
            "Epoch 30/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3543 - accuracy: 0.8882\n",
            "Epoch 31/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3463 - accuracy: 0.8918\n",
            "Epoch 32/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3461 - accuracy: 0.8933\n",
            "Epoch 33/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3413 - accuracy: 0.8944\n",
            "Epoch 34/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3403 - accuracy: 0.8921\n",
            "Epoch 35/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3344 - accuracy: 0.8952\n",
            "Epoch 36/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3324 - accuracy: 0.8967\n",
            "Epoch 37/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3256 - accuracy: 0.8974\n",
            "Epoch 38/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3238 - accuracy: 0.9001\n",
            "Epoch 39/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3224 - accuracy: 0.8987\n",
            "Epoch 40/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3165 - accuracy: 0.9000\n",
            "Epoch 41/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3159 - accuracy: 0.8985\n",
            "Epoch 42/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3152 - accuracy: 0.9033\n",
            "Epoch 43/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3087 - accuracy: 0.9041\n",
            "Epoch 44/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3066 - accuracy: 0.9024\n",
            "Epoch 45/45\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3082 - accuracy: 0.9028\n",
            "7 True one_conv\n",
            "Test accuracy: 0.8592857122421265\n",
            "Model: \"model_52\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_57 (InputLayer)       [(None, 28, 1)]           0         \n",
            "                                                                 \n",
            " conv1d_91 (Conv1D)          (None, 26, 32)            128       \n",
            "                                                                 \n",
            " flatten_27 (Flatten)        (None, 832)               0         \n",
            "                                                                 \n",
            " dense_156 (Dense)           (None, 16)                13328     \n",
            "                                                                 \n",
            " dense_157 (Dense)           (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_158 (Dense)           (None, 7)                 63        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,655\n",
            "Trainable params: 13,655\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/45\n",
            "350/350 [==============================] - 7s 16ms/step - loss: 0.6652 - accuracy: 0.6145\n",
            "Epoch 2/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.6117 - accuracy: 0.6884\n",
            "Epoch 3/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.5330 - accuracy: 0.7190\n",
            "Epoch 4/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.4916 - accuracy: 0.7351\n",
            "Epoch 5/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.4730 - accuracy: 0.7502\n",
            "Epoch 6/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.4559 - accuracy: 0.7586\n",
            "Epoch 7/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.4460 - accuracy: 0.7633\n",
            "Epoch 8/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.4344 - accuracy: 0.7698\n",
            "Epoch 9/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.4212 - accuracy: 0.7737\n",
            "Epoch 10/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.4121 - accuracy: 0.7781\n",
            "Epoch 11/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.4016 - accuracy: 0.7861\n",
            "Epoch 12/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3938 - accuracy: 0.7883\n",
            "Epoch 13/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3841 - accuracy: 0.7908\n",
            "Epoch 14/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3806 - accuracy: 0.7935\n",
            "Epoch 15/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3720 - accuracy: 0.7983\n",
            "Epoch 16/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3685 - accuracy: 0.7999\n",
            "Epoch 17/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3591 - accuracy: 0.8033\n",
            "Epoch 18/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3573 - accuracy: 0.8050\n",
            "Epoch 19/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3516 - accuracy: 0.8042\n",
            "Epoch 20/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3460 - accuracy: 0.8123\n",
            "Epoch 21/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3382 - accuracy: 0.8122\n",
            "Epoch 22/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3371 - accuracy: 0.8158\n",
            "Epoch 23/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3330 - accuracy: 0.8166\n",
            "Epoch 24/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3301 - accuracy: 0.8178\n",
            "Epoch 25/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3268 - accuracy: 0.8171\n",
            "Epoch 26/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3284 - accuracy: 0.8181\n",
            "Epoch 27/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3207 - accuracy: 0.8230\n",
            "Epoch 28/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3212 - accuracy: 0.8208\n",
            "Epoch 29/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3171 - accuracy: 0.8235\n",
            "Epoch 30/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3137 - accuracy: 0.8254\n",
            "Epoch 31/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3122 - accuracy: 0.8289\n",
            "Epoch 32/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3127 - accuracy: 0.8247\n",
            "Epoch 33/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3102 - accuracy: 0.8263\n",
            "Epoch 34/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3069 - accuracy: 0.8285\n",
            "Epoch 35/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3077 - accuracy: 0.8296\n",
            "Epoch 36/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3023 - accuracy: 0.8307\n",
            "Epoch 37/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3045 - accuracy: 0.8321\n",
            "Epoch 38/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.2995 - accuracy: 0.8337\n",
            "Epoch 39/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.3001 - accuracy: 0.8346\n",
            "Epoch 40/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.2980 - accuracy: 0.8350\n",
            "Epoch 41/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.2970 - accuracy: 0.8324\n",
            "Epoch 42/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.2948 - accuracy: 0.8355\n",
            "Epoch 43/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.2923 - accuracy: 0.8364\n",
            "Epoch 44/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.2905 - accuracy: 0.8364\n",
            "Epoch 45/45\n",
            "350/350 [==============================] - 6s 16ms/step - loss: 0.2919 - accuracy: 0.8351\n",
            "1 False five_conv\n",
            "Test accuracy: 0.7112500071525574\n",
            "Model: \"model_53\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_58 (InputLayer)       [(None, 1000, 1)]         0         \n",
            "                                                                 \n",
            " conv1d_92 (Conv1D)          (None, 999, 32)           96        \n",
            "                                                                 \n",
            " max_pooling1d_47 (MaxPoolin  (None, 499, 32)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_93 (Conv1D)          (None, 498, 256)          16640     \n",
            "                                                                 \n",
            " dropout_96 (Dropout)        (None, 498, 256)          0         \n",
            "                                                                 \n",
            " conv1d_94 (Conv1D)          (None, 497, 128)          65664     \n",
            "                                                                 \n",
            " max_pooling1d_48 (MaxPoolin  (None, 248, 128)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_95 (Conv1D)          (None, 247, 64)           16448     \n",
            "                                                                 \n",
            " dropout_97 (Dropout)        (None, 247, 64)           0         \n",
            "                                                                 \n",
            " conv1d_96 (Conv1D)          (None, 246, 32)           4128      \n",
            "                                                                 \n",
            " flatten_28 (Flatten)        (None, 7872)              0         \n",
            "                                                                 \n",
            " dense_159 (Dense)           (None, 16)                125968    \n",
            "                                                                 \n",
            " dense_160 (Dense)           (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_161 (Dense)           (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 229,089\n",
            "Trainable params: 229,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/45\n",
            "350/350 [==============================] - 3s 5ms/step - loss: 0.5687 - accuracy: 0.6916\n",
            "Epoch 2/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.5016 - accuracy: 0.7436\n",
            "Epoch 3/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4765 - accuracy: 0.7581\n",
            "Epoch 4/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4568 - accuracy: 0.7714\n",
            "Epoch 5/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4453 - accuracy: 0.7745\n",
            "Epoch 6/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4363 - accuracy: 0.7802\n",
            "Epoch 7/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4289 - accuracy: 0.7838\n",
            "Epoch 8/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4249 - accuracy: 0.7862\n",
            "Epoch 9/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4208 - accuracy: 0.7914\n",
            "Epoch 10/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4150 - accuracy: 0.7899\n",
            "Epoch 11/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4141 - accuracy: 0.7926\n",
            "Epoch 12/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4083 - accuracy: 0.7938\n",
            "Epoch 13/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4069 - accuracy: 0.7930\n",
            "Epoch 14/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.4022 - accuracy: 0.7961\n",
            "Epoch 15/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3988 - accuracy: 0.7989\n",
            "Epoch 16/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3956 - accuracy: 0.8006\n",
            "Epoch 17/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3979 - accuracy: 0.7962\n",
            "Epoch 18/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3935 - accuracy: 0.7992\n",
            "Epoch 19/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3895 - accuracy: 0.8000\n",
            "Epoch 20/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3895 - accuracy: 0.8015\n",
            "Epoch 21/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3855 - accuracy: 0.8028\n",
            "Epoch 22/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3838 - accuracy: 0.8062\n",
            "Epoch 23/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3832 - accuracy: 0.8035\n",
            "Epoch 24/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3812 - accuracy: 0.8029\n",
            "Epoch 25/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3761 - accuracy: 0.8060\n",
            "Epoch 26/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3772 - accuracy: 0.8046\n",
            "Epoch 27/45\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.3763 - accuracy: 0.8080\n",
            "Epoch 28/45\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.3752 - accuracy: 0.8070\n",
            "Epoch 29/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3734 - accuracy: 0.8076\n",
            "Epoch 30/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3697 - accuracy: 0.8099\n",
            "Epoch 31/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3701 - accuracy: 0.8068\n",
            "Epoch 32/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3711 - accuracy: 0.8070\n",
            "Epoch 33/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3683 - accuracy: 0.8074\n",
            "Epoch 34/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3659 - accuracy: 0.8108\n",
            "Epoch 35/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3633 - accuracy: 0.8140\n",
            "Epoch 36/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3642 - accuracy: 0.8127\n",
            "Epoch 37/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3603 - accuracy: 0.8142\n",
            "Epoch 38/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3615 - accuracy: 0.8156\n",
            "Epoch 39/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3579 - accuracy: 0.8161\n",
            "Epoch 40/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3585 - accuracy: 0.8146\n",
            "Epoch 41/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3584 - accuracy: 0.8139\n",
            "Epoch 42/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3612 - accuracy: 0.8126\n",
            "Epoch 43/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3581 - accuracy: 0.8145\n",
            "Epoch 44/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3567 - accuracy: 0.8151\n",
            "Epoch 45/45\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.3577 - accuracy: 0.8111\n",
            "1 True five_conv\n",
            "Test accuracy: 0.8008928298950195\n",
            "Model: \"model_54\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_59 (InputLayer)       [(None, 28, 1)]           0         \n",
            "                                                                 \n",
            " conv1d_97 (Conv1D)          (None, 27, 32)            96        \n",
            "                                                                 \n",
            " max_pooling1d_49 (MaxPoolin  (None, 13, 32)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_98 (Conv1D)          (None, 12, 256)           16640     \n",
            "                                                                 \n",
            " dropout_98 (Dropout)        (None, 12, 256)           0         \n",
            "                                                                 \n",
            " conv1d_99 (Conv1D)          (None, 11, 128)           65664     \n",
            "                                                                 \n",
            " max_pooling1d_50 (MaxPoolin  (None, 5, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_100 (Conv1D)         (None, 4, 64)             16448     \n",
            "                                                                 \n",
            " dropout_99 (Dropout)        (None, 4, 64)             0         \n",
            "                                                                 \n",
            " conv1d_101 (Conv1D)         (None, 3, 32)             4128      \n",
            "                                                                 \n",
            " flatten_29 (Flatten)        (None, 96)                0         \n",
            "                                                                 \n",
            " dense_162 (Dense)           (None, 16)                1552      \n",
            "                                                                 \n",
            " dense_163 (Dense)           (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_164 (Dense)           (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 104,673\n",
            "Trainable params: 104,673\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/45\n",
            "175/175 [==============================] - 4s 17ms/step - loss: 1.3599 - accuracy: 0.4791\n",
            "Epoch 2/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.8935 - accuracy: 0.6763\n",
            "Epoch 3/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.7057 - accuracy: 0.7493\n",
            "Epoch 4/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.5921 - accuracy: 0.7895\n",
            "Epoch 5/45\n",
            "175/175 [==============================] - 3s 16ms/step - loss: 0.5080 - accuracy: 0.8230\n",
            "Epoch 6/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.4446 - accuracy: 0.8422\n",
            "Epoch 7/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.4022 - accuracy: 0.8611\n",
            "Epoch 8/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.3500 - accuracy: 0.8752\n",
            "Epoch 9/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.3321 - accuracy: 0.8837\n",
            "Epoch 10/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.3109 - accuracy: 0.8924\n",
            "Epoch 11/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.2816 - accuracy: 0.9029\n",
            "Epoch 12/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.2631 - accuracy: 0.9081\n",
            "Epoch 13/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.2515 - accuracy: 0.9101\n",
            "Epoch 14/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.2287 - accuracy: 0.9194\n",
            "Epoch 15/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.2118 - accuracy: 0.9255\n",
            "Epoch 16/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.2093 - accuracy: 0.9252\n",
            "Epoch 17/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.2089 - accuracy: 0.9271\n",
            "Epoch 18/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.1922 - accuracy: 0.9331\n",
            "Epoch 19/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.1817 - accuracy: 0.9371\n",
            "Epoch 20/45\n",
            "175/175 [==============================] - 3s 16ms/step - loss: 0.1679 - accuracy: 0.9417\n",
            "Epoch 21/45\n",
            "175/175 [==============================] - 3s 16ms/step - loss: 0.1724 - accuracy: 0.9400\n",
            "Epoch 22/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.1627 - accuracy: 0.9438\n",
            "Epoch 23/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.1505 - accuracy: 0.9488\n",
            "Epoch 24/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.1551 - accuracy: 0.9476\n",
            "Epoch 25/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.1443 - accuracy: 0.9492\n",
            "Epoch 26/45\n",
            "175/175 [==============================] - 3s 16ms/step - loss: 0.1454 - accuracy: 0.9497\n",
            "Epoch 27/45\n",
            "175/175 [==============================] - 3s 16ms/step - loss: 0.1419 - accuracy: 0.9521\n",
            "Epoch 28/45\n",
            "175/175 [==============================] - 3s 16ms/step - loss: 0.1388 - accuracy: 0.9511\n",
            "Epoch 29/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.1242 - accuracy: 0.9556\n",
            "Epoch 30/45\n",
            "175/175 [==============================] - 3s 16ms/step - loss: 0.1216 - accuracy: 0.9575\n",
            "Epoch 31/45\n",
            "175/175 [==============================] - 3s 16ms/step - loss: 0.1209 - accuracy: 0.9593\n",
            "Epoch 32/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.1187 - accuracy: 0.9592\n",
            "Epoch 33/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.1129 - accuracy: 0.9620\n",
            "Epoch 34/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.1143 - accuracy: 0.9614\n",
            "Epoch 35/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.1123 - accuracy: 0.9615\n",
            "Epoch 36/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.1051 - accuracy: 0.9648\n",
            "Epoch 37/45\n",
            "175/175 [==============================] - 3s 16ms/step - loss: 0.1041 - accuracy: 0.9643\n",
            "Epoch 38/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.1067 - accuracy: 0.9623\n",
            "Epoch 39/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.1011 - accuracy: 0.9658\n",
            "Epoch 40/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.0970 - accuracy: 0.9668\n",
            "Epoch 41/45\n",
            "175/175 [==============================] - 3s 16ms/step - loss: 0.0960 - accuracy: 0.9659\n",
            "Epoch 42/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.0891 - accuracy: 0.9687\n",
            "Epoch 43/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.0944 - accuracy: 0.9683\n",
            "Epoch 44/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.0878 - accuracy: 0.9677\n",
            "Epoch 45/45\n",
            "175/175 [==============================] - 3s 17ms/step - loss: 0.0916 - accuracy: 0.9689\n",
            "7 False five_conv\n",
            "Test accuracy: 0.8310714364051819\n",
            "Model: \"model_55\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_60 (InputLayer)       [(None, 1000, 1)]         0         \n",
            "                                                                 \n",
            " conv1d_102 (Conv1D)         (None, 999, 32)           96        \n",
            "                                                                 \n",
            " max_pooling1d_51 (MaxPoolin  (None, 499, 32)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_103 (Conv1D)         (None, 498, 256)          16640     \n",
            "                                                                 \n",
            " dropout_100 (Dropout)       (None, 498, 256)          0         \n",
            "                                                                 \n",
            " conv1d_104 (Conv1D)         (None, 497, 128)          65664     \n",
            "                                                                 \n",
            " max_pooling1d_52 (MaxPoolin  (None, 248, 128)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_105 (Conv1D)         (None, 247, 64)           16448     \n",
            "                                                                 \n",
            " dropout_101 (Dropout)       (None, 247, 64)           0         \n",
            "                                                                 \n",
            " conv1d_106 (Conv1D)         (None, 246, 32)           4128      \n",
            "                                                                 \n",
            " flatten_30 (Flatten)        (None, 7872)              0         \n",
            "                                                                 \n",
            " dense_165 (Dense)           (None, 16)                125968    \n",
            "                                                                 \n",
            " dense_166 (Dense)           (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_167 (Dense)           (None, 7)                 63        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 229,143\n",
            "Trainable params: 229,143\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/45\n",
            "175/175 [==============================] - 2s 5ms/step - loss: 1.7140 - accuracy: 0.3052\n",
            "Epoch 2/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 1.3402 - accuracy: 0.4900\n",
            "Epoch 3/45\n",
            "175/175 [==============================] - 1s 6ms/step - loss: 1.0598 - accuracy: 0.6221\n",
            "Epoch 4/45\n",
            "175/175 [==============================] - 1s 7ms/step - loss: 0.8797 - accuracy: 0.7105\n",
            "Epoch 5/45\n",
            "175/175 [==============================] - 1s 6ms/step - loss: 0.7743 - accuracy: 0.7490\n",
            "Epoch 6/45\n",
            "175/175 [==============================] - 1s 6ms/step - loss: 0.7232 - accuracy: 0.7635\n",
            "Epoch 7/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.6675 - accuracy: 0.7846\n",
            "Epoch 8/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.6414 - accuracy: 0.7900\n",
            "Epoch 9/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.6088 - accuracy: 0.8041\n",
            "Epoch 10/45\n",
            "175/175 [==============================] - 1s 6ms/step - loss: 0.5862 - accuracy: 0.8078\n",
            "Epoch 11/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.5672 - accuracy: 0.8129\n",
            "Epoch 12/45\n",
            "175/175 [==============================] - 1s 6ms/step - loss: 0.5447 - accuracy: 0.8261\n",
            "Epoch 13/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.5308 - accuracy: 0.8267\n",
            "Epoch 14/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.5087 - accuracy: 0.8321\n",
            "Epoch 15/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.4902 - accuracy: 0.8415\n",
            "Epoch 16/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.4845 - accuracy: 0.8388\n",
            "Epoch 17/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.4732 - accuracy: 0.8414\n",
            "Epoch 18/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.4567 - accuracy: 0.8520\n",
            "Epoch 19/45\n",
            "175/175 [==============================] - 1s 6ms/step - loss: 0.4488 - accuracy: 0.8514\n",
            "Epoch 20/45\n",
            "175/175 [==============================] - 1s 6ms/step - loss: 0.4357 - accuracy: 0.8554\n",
            "Epoch 21/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.4323 - accuracy: 0.8610\n",
            "Epoch 22/45\n",
            "175/175 [==============================] - 1s 6ms/step - loss: 0.4233 - accuracy: 0.8586\n",
            "Epoch 23/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.4073 - accuracy: 0.8608\n",
            "Epoch 24/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.4035 - accuracy: 0.8631\n",
            "Epoch 25/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.4004 - accuracy: 0.8661\n",
            "Epoch 26/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.3901 - accuracy: 0.8727\n",
            "Epoch 27/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.3859 - accuracy: 0.8705\n",
            "Epoch 28/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.3790 - accuracy: 0.8746\n",
            "Epoch 29/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.3680 - accuracy: 0.8747\n",
            "Epoch 30/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.3633 - accuracy: 0.8771\n",
            "Epoch 31/45\n",
            "175/175 [==============================] - 1s 6ms/step - loss: 0.3590 - accuracy: 0.8785\n",
            "Epoch 32/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.3579 - accuracy: 0.8802\n",
            "Epoch 33/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.3610 - accuracy: 0.8747\n",
            "Epoch 34/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.3524 - accuracy: 0.8803\n",
            "Epoch 35/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.3435 - accuracy: 0.8845\n",
            "Epoch 36/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.3346 - accuracy: 0.8858\n",
            "Epoch 37/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.3342 - accuracy: 0.8887\n",
            "Epoch 38/45\n",
            "175/175 [==============================] - 1s 6ms/step - loss: 0.3231 - accuracy: 0.8903\n",
            "Epoch 39/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.3322 - accuracy: 0.8879\n",
            "Epoch 40/45\n",
            "175/175 [==============================] - 1s 6ms/step - loss: 0.3238 - accuracy: 0.8906\n",
            "Epoch 41/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.3101 - accuracy: 0.8946\n",
            "Epoch 42/45\n",
            "175/175 [==============================] - 1s 6ms/step - loss: 0.3207 - accuracy: 0.8901\n",
            "Epoch 43/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.3220 - accuracy: 0.8883\n",
            "Epoch 44/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.3132 - accuracy: 0.8931\n",
            "Epoch 45/45\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.2959 - accuracy: 0.9010\n",
            "7 True five_conv\n",
            "Test accuracy: 0.8810714483261108\n",
            "Model: \"model_56\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_61 (InputLayer)       [(None, 28, 1)]           0         \n",
            "                                                                 \n",
            " conv1d_107 (Conv1D)         (None, 27, 32)            96        \n",
            "                                                                 \n",
            " max_pooling1d_53 (MaxPoolin  (None, 13, 32)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_108 (Conv1D)         (None, 12, 256)           16640     \n",
            "                                                                 \n",
            " dropout_102 (Dropout)       (None, 12, 256)           0         \n",
            "                                                                 \n",
            " conv1d_109 (Conv1D)         (None, 11, 128)           65664     \n",
            "                                                                 \n",
            " max_pooling1d_54 (MaxPoolin  (None, 5, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_110 (Conv1D)         (None, 4, 64)             16448     \n",
            "                                                                 \n",
            " dropout_103 (Dropout)       (None, 4, 64)             0         \n",
            "                                                                 \n",
            " conv1d_111 (Conv1D)         (None, 3, 32)             4128      \n",
            "                                                                 \n",
            " flatten_31 (Flatten)        (None, 96)                0         \n",
            "                                                                 \n",
            " dense_168 (Dense)           (None, 16)                1552      \n",
            "                                                                 \n",
            " dense_169 (Dense)           (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_170 (Dense)           (None, 7)                 63        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 104,727\n",
            "Trainable params: 104,727\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## combine best models for task1"
      ],
      "metadata": {
        "id": "7YDbPBeiYtXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_binary(m1, m2, X_1, X_2, y_t):\n",
        "  logits1 = m1(X_1)\n",
        "  logits2 = m2(X_2)\n",
        "  logits = (logits1 + logits2) / 2\n",
        "  y_pred = (logits > 0.5)\n",
        "  arr = np.where(y_pred, 1, 0)\n",
        "  acc = accuracy_score(y_t, arr)\n",
        "  return acc"
      ],
      "metadata": {
        "id": "sh4r243MCCh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(combine_binary(model1, model2, X_test, X_test2, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc9XamkcCNXK",
        "outputId": "8ddc8efd-21a8-40e7-c997-3fd0f9c2a361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7382142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## combine best models for task2"
      ],
      "metadata": {
        "id": "oD6x5FiVYzvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_multiclass(m1, m2, X_1, X_2, y_t):\n",
        "  logits1 = m1(X_1)\n",
        "  logits2 = m2(X_2)\n",
        "  logits = (logits1 + logits2) / 2\n",
        "  arr = tf.keras.backend.get_value(logits)\n",
        "  y_pred = np.eye(arr.shape[1])[np.argmax(arr, axis=1)]\n",
        "  acc = accuracy_score(y_t, y_pred)\n",
        "  return acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG3z9pJPDPf8",
        "outputId": "95c42235-57ae-4e8f-fef2-08740b0ee324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8992857142857142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(combine_multiclass(model3, model4, X_test3, X_test4, y_test3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fVo7dUAHz9S",
        "outputId": "0d241e8c-e7dc-48ce-e365-49c9c91df4a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8992857142857142\n"
          ]
        }
      ]
    }
  ]
}